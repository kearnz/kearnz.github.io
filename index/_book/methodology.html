<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Methodology | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning</title>
  <meta name="description" content="Methodology | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  <meta name="generator" content="bookdown  and GitBook 2.6.7" />

  <meta property="og:title" content="Methodology | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Methodology | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  
  
  

<meta name="author" content="Shahid Barkat, Joseph Kearney" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="background.html">
<link rel="next" href="findings.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#problem-statement"><i class="fa fa-check"></i>Problem Statement</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#research-purpose"><i class="fa fa-check"></i>Research Purpose</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i>Background</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-basic-terms"><i class="fa fa-check"></i>Basic Terminology and Notation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-mech"><i class="fa fa-check"></i>Missing Data Mechanism</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-mcar-mar-mnar"><i class="fa fa-check"></i>MCAR, MAR, and MNAR</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-ignorability"><i class="fa fa-check"></i>Ignorability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-methods"><i class="fa fa-check"></i>Missing Data Methods</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-deletion"><i class="fa fa-check"></i>Deletion</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-imputation"><i class="fa fa-check"></i>Imputation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-single-imputation"><i class="fa fa-check"></i>Single Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-multiple-imputation"><i class="fa fa-check"></i>Multiple Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-example"><i class="fa fa-check"></i>Single Imputation vs.Â Multiple Imputation Revisited</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis"><i class="fa fa-check"></i>Analysis Models</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-listwise"><i class="fa fa-check"></i>Analysis after Listwise Deletion</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-single"><i class="fa fa-check"></i>Analysis after Single Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-multiple"><i class="fa fa-check"></i>Analysis after Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-autoimpute"><i class="fa fa-check"></i>Missing Data and Autoimpute</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html"><i class="fa fa-check"></i>Methodology</a><ul>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#the-full-dataset"><i class="fa fa-check"></i>The Full Dataset</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#example-1-mcar-with-missingness-in-the-response"><i class="fa fa-check"></i>Example 1: MCAR with Missingness in the Response</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#example-2-mar-with-missingness-in-the-predictor"><i class="fa fa-check"></i>Example 2: MAR with Missingness in the Predictor</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#analysis-models-on-each-example"><i class="fa fa-check"></i>Analysis Models on each Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html"><i class="fa fa-check"></i>Findings</a><ul>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#full-model-recap"><i class="fa fa-check"></i>Full Model Recap</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#results-from-example-1"><i class="fa fa-check"></i>Results from Example 1</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#results-from-example-2"><i class="fa fa-check"></i>Results from Example 2</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#analysis-of-results"><i class="fa fa-check"></i>Analysis of Results</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="chapter" data-level="" data-path="recommendations.html"><a href="recommendations.html"><i class="fa fa-check"></i>Recommendations</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-autoimpute-references.html"><a href="A-autoimpute-references.html"><i class="fa fa-check"></i><b>A</b> Autoimpute References</a></li>
<li class="chapter" data-level="B" data-path="B-missingness-notation-cheatsheet.html"><a href="B-missingness-notation-cheatsheet.html"><i class="fa fa-check"></i><b>B</b> Missingness Notation Cheatsheet</a></li>
<li class="chapter" data-level="C" data-path="C-missingess-expression-cheatsheet.html"><a href="C-missingess-expression-cheatsheet.html"><i class="fa fa-check"></i><b>C</b> Missingess Expression Cheatsheet</a></li>
<li class="chapter" data-level="D" data-path="D-concepts-related-to-missingness.html"><a href="D-concepts-related-to-missingness.html"><i class="fa fa-check"></i><b>D</b> Concepts Related to Missingness</a></li>
<li class="chapter" data-level="E" data-path="E-univariate-imputation-methods.html"><a href="E-univariate-imputation-methods.html"><i class="fa fa-check"></i><b>E</b> Univariate Imputation Methods</a></li>
<li class="chapter" data-level="F" data-path="F-multivariate-imputation-methods.html"><a href="F-multivariate-imputation-methods.html"><i class="fa fa-check"></i><b>F</b> Multivariate Imputation Methods</a></li>
<li class="chapter" data-level="G" data-path="G-analysis-models-and-diagnostics.html"><a href="G-analysis-models-and-diagnostics.html"><i class="fa fa-check"></i><b>G</b> Analysis Models and Diagnostics</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methodology" class="section level1 unnumbered">
<h1>Methodology</h1>
<p>The missing data methods introduced in the background section are a subset of those available in <code>Autoimpute</code>. Beyond <code>Autoimpute</code> numerous additional missing data methods exist to handle missing data, and they are continuously being developed and improved (Schouten, et al, 2018). Therefore, it is vital to understand under which circumstances each imputation technique can be used, and it is important to evaluate each technique in relation to other methods (Schouten, et al, 2018). To do so, researchers can simulate complete datasets and introduce different types of missing data mechanisms and missing data patterns. Such a procedure affords the researcher an opportunity to evaluate imputation methods and their affect on analysis models under different circumstances (Schouten, et al, 2018).</p>
<p>In this research, the authors explore the performance of imputation methods and their effect on analysis models under two separate circumstances. The authors begin by simulating a dataset with no missingness. A simple linear regression is performed on this simulated dataset and its coefficients are stored as benchmarks. Next, the researchers impose two different types of missingness mechanisms and missing data patterns on the complete dataset. This procedure produces two disctinct, incomplete datasets, where the remaining observed values are the same as the original but now some observations are missing. The authors then impose the same deletion and impution methods on each of the incomplete datasets using the multiple imputation framework. Finally, the authors apply the same linear regression model to the multiply imputed data and pool the parameter estimates and variance. The authors then compare the results from each process to each other and to the results from linear regression on the original complete dataset. The authors perform the entire process using the <code>Autoimpute</code> package, which demonstrates its capabilities as an end-to-end framework for handling missing data.</p>
<p>In each example, the researchers then explore missingness patterns within the dataset. Then, the authors use the following missing data methods:</p>
<ul>
<li>Listwise deletion or CCA</li>
<li>Mean imputation</li>
<li>Least Squares imputation</li>
<li>Predictive Mean Matching</li>
</ul>
<p><code>Autoimpute</code> offers many more missing data methods, but these four are useful for examination because each carries a different set of assumptions and takes a very different approach to imputing missing values. CCA is a deletion method, so it ignores missingness entirely by discarding records with any missing observations. Mean imputation is a univariate method, so it disregards any structure between the target variable and other features. Least squares is a popular supervised multivariate method familiar to readers. And PMM is an advanced semi-supervised multivariate method that blends concepts from bayesian analysis, linear regression, and k-nearest neighbors. The sections below demonstrate when these methods work and when they do not. As always, their performance is directly linked to the nature of missingness within a dataset. Therefore, some methods shine in circumstances where other methods underperform.</p>
<div id="the-full-dataset" class="section level2 unnumbered">
<h2>The Full Dataset</h2>
<p>The authors begin by simulating the full dataset, which they use as the source of truth. The full dataset contains 500 observations for feature <span class="math inline">\(x\)</span> and response <span class="math inline">\(y\)</span>. At this point, no missingness exists in either <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span></p>
<p>The figure below visualizes the distribution of each variable:</p>
<div class="figure" style="text-align: center"><span id="fig:fullsidebyside"></span>
<img src="figure/full-side-by-side.jpg" alt="Distribution of Full x and y" width="300px" />
<p class="caption">
Figure .: Distribution of Full x and y
</p>
</div>
<p>The next figure displays the joint relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. The figure plots the marginal distribution of each variable as well:</p>
<div class="figure" style="text-align: center"><span id="fig:full-joint"></span>
<img src="figure/full-joint.jpg" alt="Joint and Marginals of Full x and y" width="300px" />
<p class="caption">
Figure .: Joint and Marginals of Full x and y
</p>
</div>
<p>The full dataset does not contain any missing values. Therefore, we do not have to perform any imputation before we conduct analysis. Using <code>Autoimpute</code>, the researchers fit a linear regression model on the full dataset. The summary of the model fit appears below:</p>
<div class="figure" style="text-align: center"><span id="fig:full-regression"></span>
<img src="figure/full-regression.jpg" alt="Linear Regression Results: Full" width="300px" />
<p class="caption">
Figure .: Linear Regression Results: Full
</p>
</div>
<p>The results from linear regression on the full dataset serve as the golden source. The coefficient estimate for <span class="math inline">\(x\)</span> is 0.5. Using notation related to imputation analysis, this coefficient estimate of <span class="math inline">\(x\)</span> represents <span class="math inline">\(\hat Q\)</span> - the unbiased estimate of the population parameter of interest <span class="math inline">\(Q\)</span>. Because there is only one predictor, the covariance matrix <span class="math inline">\(U\)</span> simply reduces to the variance of the estimate.</p>
<p>The summary output above displays diagnostics for the linear regression model. The table uses aliases for concepts covered in the background section and introduces some new terminology. They are:</p>
<ul>
<li><code>coefs</code> - The parameter estimate <span class="math inline">\(\hat Q\)</span></li>
<li><code>std</code> - The standard error of the coefficient estimate</li>
<li><code>vw</code> - The variance-within <span class="math inline">\(\bar U\)</span></li>
<li><code>vb</code> - The variance-between <span class="math inline">\(B\)</span></li>
<li><code>vt</code> - The total variance <span class="math inline">\(T\)</span></li>
<li><code>dfcom</code> - The degrees of freedom for the hypothetically complete dataset</li>
<li><code>dfadj</code> - Adapted degrees of freedom for samples that have missing data</li>
<li><code>lambda</code> - The proportion of variance due to nonresponse or missingness</li>
<li><code>riv</code> - The relative increase in variance due to nonresponse or missingness</li>
</ul>
<p>Observe that <code>vb</code>, <code>lambda</code>, and <code>riv</code> are all equal to 0. This result occurs because no missingness exists and multiple imputation is not used. These diagnostics are of interest for methods that produce variability in imputed values when using mutliple imputation. Therefore, values for <code>coefs</code>, <code>std</code>, and <code>vw</code> are the values of interest. They are the benchmarks for comparison when the authors reproduce this analysis on variants of the full dataset that have artificial missingness introduced. The rest of the diagnostics will become clear in the next sections.</p>
</div>
<div id="example-1-mcar-with-missingness-in-the-response" class="section level2 unnumbered">
<h2>Example 1: MCAR with Missingness in the Response</h2>
<p>In the first example, the researchers generate MCAR missingness within the response, <span class="math inline">\(y\)</span>. Response <span class="math inline">\(y\)</span> contains 40% missing values. Feature <span class="math inline">\(x\)</span> remains fully observed. The two plots below showcase how to use <code>Autoimpute</code> to explore missingness within a given dataset. The plots are quite simple in this case, but they can help detect patterns in missing data when multiple features are present with different levels of missingness.</p>
<div class="figure" style="text-align: center"><span id="fig:y-mis-forty-loc"></span>
<img src="figure/y-mis-forty-loc.jpg" alt="Missingness Locations" width="300px" />
<p class="caption">
Figure .: Missingness Locations
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:y-mis-forty-bar"></span>
<img src="figure/y-mis-forty-bar.jpg" alt="Missingness Percentage" width="300px" />
<p class="caption">
Figure .: Missingness Percentage
</p>
</div>
<p>Next, the researchers employ missing data methods to handle missing data. In this case, missing data methods must find plausible imputations for the 40% of <span class="math inline">\(y\)</span> that is missing. The imputation methods used include mean, linear regression, and pmm. The researchers also use listwise deletion, although there is no visualization within <code>Autoimpute</code> for complete-case analysis because no imputations are performed. For imputation methods, the researchers deploy each strategy within the multiple imputation framework. The number of imputations performed for each method is 5.</p>
<p>The visualizations below show the impact of mean, linear regression, and pmm. For each strategy, there are two respective plots. The first plot is the new multivariate distribution between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> after imputation. The second plot is a swarm plot that shows the imputations for <span class="math inline">\(y\)</span> against other, observed values for <span class="math inline">\(y\)</span> for each of the <span class="math inline">\(5\)</span> imputations performed.</p>
<p>Letâs start with mean imputation:</p>
<div class="figure" style="text-align: center"><span id="fig:multi-mean"></span>
<img src="figure/multi-mean.jpg" alt="Joint and Marginals with Mean Imputation" width="300px" />
<p class="caption">
Figure .: Joint and Marginals with Mean Imputation
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:swarm-mean"></span>
<img src="figure/swarm-mean.jpg" alt="Swarm Plot: Mean Imputation" width="300px" />
<p class="caption">
Figure .: Swarm Plot: Mean Imputation
</p>
</div>
<p>Note that for mean imputation, the imputations do not depend on the value of <span class="math inline">\(x\)</span>, and the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is ignored. This result makes sense, as mean imputation is a univariate method. Also note that the imputation values in the swarm plot are the same for each imputation. This occurs because the mean of the observed values of <span class="math inline">\(y\)</span> do not change from imputation to imputation within the multiple imputation framework. Therefore, the imputation values within each imputed dataset are the same, and the imputation values accross each imputed dataset are the same.</p>
<p>Next, observe imputation via least squares:</p>
<div class="figure" style="text-align: center"><span id="fig:multi-lm"></span>
<img src="figure/multi-lm.jpg" alt="Joint and Marginals with Least Squares Imputation" width="300px" />
<p class="caption">
Figure .: Joint and Marginals with Least Squares Imputation
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:swarm-lm"></span>
<img src="figure/swarm-lm.jpg" alt="Swarm Plot: Least Squares Imputation" width="300px" />
<p class="caption">
Figure .: Swarm Plot: Least Squares Imputation
</p>
</div>
<p>The plots for linear regression now take into account the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>. As a result, the imputed values are different within imputations but the same across imputations. Within imputations, the linear model produces different results, which depend on the value of <span class="math inline">\(x\)</span>. But across imputations, the linear model is the same because it is fit to the same data and no random error is added to imputations.</p>
<p>Finally, observe pmm imputation:</p>
<div class="figure" style="text-align: center"><span id="fig:multi-pmm"></span>
<img src="figure/multi-pmm.jpg" alt="Joint and Marginals with PMM Imputation" width="300px" />
<p class="caption">
Figure .: Joint and Marginals with PMM Imputation
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:swarm-pmm"></span>
<img src="figure/swarm-pmm.jpg" alt="Swarm Plot: PMM Imputation" width="300px" />
<p class="caption">
Figure .: Swarm Plot: PMM Imputation
</p>
</div>
<p>PMM Imputation respects not only the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> but also the variance between the features. Imputations are no longer from the âline of best fitâ as they are with linear regression. Additionally, imputations are different within and across imputations. Therefore, PMM does the best job at respecting the structure of the data and adding variance between / across imputed datasets.</p>
</div>
<div id="example-2-mar-with-missingness-in-the-predictor" class="section level2 unnumbered">
<h2>Example 2: MAR with Missingness in the Predictor</h2>
<p>In the second example, the researchers generate MAR missingness within the predictor, <span class="math inline">\(x\)</span>. Predictor <span class="math inline">\(x\)</span> contains 40% missing values. Response <span class="math inline">\(y\)</span> remains fully observed. To keep this section concise, we will not generate the same plots that we did above, but we will apply the exact same methods. <code>Autoimpute</code> can impute both features and predictors, and it can examine missingness anywhere it exists within a dataset.</p>
<p>The researchers take the same approach to Example 2 as they do to Example 1. Multiple imputation is performed, with the number of imputations equal to 5. The same methods are applied as well (listwise delete, mean, least squares, and pmm).</p>
</div>
<div id="analysis-models-on-each-example" class="section level2 unnumbered">
<h2>Analysis Models on each Example</h2>
<p>The sections above take the user through the data exploration phase and multiple imputation phase of <code>Autoimpute</code>. The next section, Findings, demonstrates how the nature of missingness affected the results of linear regression on our mulitply imputed data.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="background.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="findings.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["capstone.pdf", "PDF"], ["capstone.epub", "EPUB"], ["capstone.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
