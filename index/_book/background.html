<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Background | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning</title>
  <meta name="description" content="Background | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  <meta name="generator" content="bookdown  and GitBook 2.6.7" />

  <meta property="og:title" content="Background | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Background | Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning" />
  
  
  

<meta name="author" content="Shahid Barkat, Joseph Kearney" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html">
<link rel="next" href="methodology.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#problem-statement"><i class="fa fa-check"></i>Problem Statement</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#research-purpose"><i class="fa fa-check"></i>Research Purpose</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i>Background</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-basic-terms"><i class="fa fa-check"></i>Basic Terminology and Notation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-mech"><i class="fa fa-check"></i>Missing Data Mechanism</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-mcar-mar-mnar"><i class="fa fa-check"></i>MCAR, MAR, and MNAR</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-ignorability"><i class="fa fa-check"></i>Ignorability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-methods"><i class="fa fa-check"></i>Missing Data Methods</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-deletion"><i class="fa fa-check"></i>Deletion</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-imputation"><i class="fa fa-check"></i>Imputation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-single-imputation"><i class="fa fa-check"></i>Single Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-multiple-imputation"><i class="fa fa-check"></i>Multiple Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-example"><i class="fa fa-check"></i>Single Imputation vs. Multiple Imputation Revisited</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis"><i class="fa fa-check"></i>Analysis Models</a><ul>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-listwise"><i class="fa fa-check"></i>Analysis after Listwise Deletion</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-single"><i class="fa fa-check"></i>Analysis after Single Imputation</a></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-analysis-multiple"><i class="fa fa-check"></i>Analysis after Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="background.html"><a href="background.html#background-missing-data-autoimpute"><i class="fa fa-check"></i>Missing Data and Autoimpute</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html"><i class="fa fa-check"></i>Methodology</a><ul>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#the-full-dataset"><i class="fa fa-check"></i>The Full Dataset</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#example-1-mcar-with-missingness-in-the-response"><i class="fa fa-check"></i>Example 1: MCAR with Missingness in the Response</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#example-2-mar-with-missingness-in-the-predictor"><i class="fa fa-check"></i>Example 2: MAR with Missingness in the Predictor</a></li>
<li class="chapter" data-level="" data-path="methodology.html"><a href="methodology.html#analysis-models-on-each-example"><i class="fa fa-check"></i>Analysis Models on each Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html"><i class="fa fa-check"></i>Findings</a><ul>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#full-model-recap"><i class="fa fa-check"></i>Full Model Recap</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#results-from-example-1"><i class="fa fa-check"></i>Results from Example 1</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#results-from-example-2"><i class="fa fa-check"></i>Results from Example 2</a></li>
<li class="chapter" data-level="" data-path="findings.html"><a href="findings.html#analysis-of-results"><i class="fa fa-check"></i>Analysis of Results</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i>Conclusion</a></li>
<li class="chapter" data-level="" data-path="recommendations.html"><a href="recommendations.html"><i class="fa fa-check"></i>Recommendations</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-autoimpute-references.html"><a href="A-autoimpute-references.html"><i class="fa fa-check"></i><b>A</b> Autoimpute References</a></li>
<li class="chapter" data-level="B" data-path="B-notation-cheatsheet.html"><a href="B-notation-cheatsheet.html"><i class="fa fa-check"></i><b>B</b> Notation Cheatsheet</a></li>
<li class="chapter" data-level="C" data-path="C-concepts-related-to-missingness.html"><a href="C-concepts-related-to-missingness.html"><i class="fa fa-check"></i><b>C</b> Concepts Related to Missingness</a></li>
<li class="chapter" data-level="D" data-path="D-univariate-imputation-methods.html"><a href="D-univariate-imputation-methods.html"><i class="fa fa-check"></i><b>D</b> Univariate Imputation Methods</a></li>
<li class="chapter" data-level="E" data-path="E-multivariate-imputation-methods.html"><a href="E-multivariate-imputation-methods.html"><i class="fa fa-check"></i><b>E</b> Multivariate Imputation Methods</a></li>
<li class="chapter" data-level="F" data-path="F-analysis-models-and-diagnostics.html"><a href="F-analysis-models-and-diagnostics.html"><i class="fa fa-check"></i><b>F</b> Analysis Models and Diagnostics</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analytics as a Service (DAaaS): Automated &amp; Intelligent Imputation Methods for Supervised Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="background" class="section level1 unnumbered">
<h1>Background</h1>
<p>One must understand what missingness is and why it exists before deciding how to handle it. The authors explore the nature of missingness using a motivating example.</p>
<p>For an experiment, assume that a random sample of measurements is collected from thousands of weigh scales. Also assume each weigh scale in the experiment may fail to produce measurements for three separate reasons. First, a scale might run out of batteries, in which case all measurements from that scale cease for a given period of time. Next, a scale may fail more frequently for heavier objects or items over a certain weight threshhold. And finally, a scale may stop reporting measurements when placed on a soft surface instead of a hard one (Van Buuren, 2018, ch. 1.2).</p>
<p>As a result of these scenarios, the random sample collected likely has many instances in which weight measurements are unobserved. How missingness in this sample is handled moving forward will depend on characteristics of the missing data itself and the process that generated missingess. The authors devote the rest of this section to concepts related to the nature of missingness and how it is handled. The authors refer back to this example to make concepts more concrete.</p>
<div id="background-basic-terms" class="section level2 unnumbered">
<h2>Basic Terminology and Notation</h2>
<p>Before diving into concepts related to missingness, the authors establish notation used throughout this text. In doing so, the authors also introduce some basic terminology. This research follows the notation Van Buuren uses in the second edition of his book, Flexible Imputation of Missing Data. For more information, refer to Appendix B, which collects and summarizes the notation seen throughout this research.</p>
<p>In the introductory example, weigh scales produce a set of <span class="math inline">\(n\)</span> measurements, some of which may be missing weight. <span class="math inline">\(Y\)</span> denotes the <span class="math inline">\(n\)</span> x <span class="math inline">\(p\)</span> matrix that contains the <span class="math inline">\(n\)</span> measurements and the <span class="math inline">\(p\)</span> variables recorded along with the measurements. The surface of the scale (hard or soft) is an example of a discrete variable in <span class="math inline">\(p\)</span>, while the weight measurement itself is a continuous variable in <span class="math inline">\(p\)</span>. We can retrieve an observation within <span class="math inline">\(Y\)</span> by specifying the row and column index corresponding to the observation’s cell. To do so, we use the notation <span class="math inline">\(y_{ij}\)</span>, where <span class="math inline">\(i\)</span> represents the row and <span class="math inline">\(j\)</span> represents the column associated with a scalar <span class="math inline">\(y\)</span> in matrix <span class="math inline">\(Y\)</span>.</p>
<p><span class="math inline">\(Y\)</span> itself represents the hypothetically complete data (Van Buuren, 2018, ch. 2.2.3), which is comprised of <span class="math inline">\(Y_{obs}\)</span> and <span class="math inline">\(Y_{mis}\)</span>. <span class="math inline">\(Y_{obs}\)</span> represents each row <span class="math inline">\(Y_i\)</span> out of <span class="math inline">\(n\)</span> records that have known values for each column <span class="math inline">\(Y_j\)</span> in <span class="math inline">\(p\)</span>. <span class="math inline">\(Y_{mis}\)</span>, on the other hand, contains records with missing observations across any of the columns in <span class="math inline">\(p\)</span>. Note that <span class="math inline">\(Y = (Y_{obs}, Y_{mis})\)</span>. The hypothetically complete data equals the conjoined observed and missing data matrices.</p>
<p>It is convenient to store whether or not a cell in <span class="math inline">\(Y\)</span> is missing in a separate matrix <span class="math inline">\(R\)</span>. Therefore, <span class="math inline">\(R\)</span> is an <span class="math inline">\(n\)</span> by <span class="math inline">\(p\)</span> matrix where all entries <span class="math inline">\(r_{ij} \in {0, 1}\)</span>. Any observation <span class="math inline">\(r_{ij}=1\)</span> corresponds to a known value for <span class="math inline">\(y_{ij}\)</span>. On the contrary, any observation <span class="math inline">\(r_{ij}=0\)</span> corresponds to a missing value for <span class="math inline">\(y_{ij}\)</span>. <span class="math inline">\(R\)</span> is commonly referred to as the <strong>missing indicator matrix</strong>, while <span class="math inline">\(Y\)</span> is the <strong>complete data matrix</strong> (Van Buuren, 2018, ch. 2.2.3).</p>
</div>
<div id="background-missing-data-mech" class="section level2 unnumbered">
<h2>Missing Data Mechanism</h2>
<p>Each of the three scenarios discussed above causes a given weigh scale to produce missing data, but the underlying reason for missingness is quite different in each case. Donald Rubin describes the ways in which data can be missing (Rubin, 1976). According to Rubin (as cited in Van Buuren, 2018, ch. 1.2), every observation in a dataset has some probability of being missing. The process that governs these probabilities is called the <strong>missing data mechanism</strong> (Rubin, as cited in Van Buuren, 2018, ch. 1.2). The missing data mechanism generates a statistical relationship between observations and the probability of missing data (Nakagawa, 2015, pg. 83). The <strong>missing data model</strong> is the function that formalizes that statistical relationship (Van Buuren, 2018, ch. 2.2.4). These statistical relationships fall into one of three categories, each of which represents a different missing data mechanism (Rubin, as cited in Van Buuren, 2018, ch. 1.2).</p>
<p>The general expression for the missing data model is defined as:</p>
<p><span class="math display">\[P(R|Y_{obs}, Y_{mis},\psi)\]</span></p>
<p><span class="math inline">\(\psi\)</span> cointains the parameters of the missing data model. This expression notes that the probability of missingness <span class="math inline">\(P(R=0)\)</span> within a dataset depends on the observed data, the missing data, and the missing data model’s parameters. (Van Buuren, 2018, ch. 2.2.4). From another lense, this expession states that the missing data model is the distribution of the missingness indicator conditional on the observed data, the missing data, and the parameters of the missing data model.</p>
<p>The missing data model is the function that formalizes the statistical relationship governed by a missing data mechanism. The next section examines the manifestation of the missing data model under each mechanism.</p>
<div id="background-mcar-mar-mnar" class="section level3 unnumbered">
<h3>MCAR, MAR, and MNAR</h3>
<p>Rubin popularized names for the three categories that represent the main missing data mechanisms:</p>
<ul>
<li><strong>Missing Completely at Random (MCAR)</strong></li>
<li><strong>Missing at Random (MAR)</strong></li>
<li><strong>Missing Not at Random (MNAR)</strong></li>
</ul>
<p>In this research, the authors refer to each category by its abbreviated label. The subsections below examine each category in more detail.</p>
<div id="mcar" class="section level4 unnumbered">
<h4>Missing Completely at Random (MCAR)</h4>
<p>MCAR is the first of the three missing data mechanisms. MCAR assumes missing values in the underlying dataset have the same probability of missingness for all cases (Gelman &amp; Hill, 2017, pg. 530). Thus, MCAR implies that the probability of missingness within a dataset is completely unrelated to the data in question or any other observed or unobserved data. The missing data model associated with MCAR is defined as:</p>
<p><span class="math display">\[P(R=0|Y_{obs},Y_{mis},\psi) = P(R=0|\psi)\]</span></p>
<p>Note that the general expression of the missing data model reduces to a much simpler form. Under MCAR, the probability of data being missing depends on the parameters of the missing data only and not on the values of missing data itself or the value of any of the observed data (Van Buuren, 2018, ch. 2.2.4).</p>
<p>From the weigh scale example, MCAR governs the probability of values being missing from a scale that runs out of batteries at some point in time (Van Buuren, 2018, ch. 1.2). For simplicity, assume time is not a latent variable nor of interest in the data collection process. In this case then, the missing values produced from the scale do not depend on the weight of the object in question nor the surface used for the scale, so the probability a value is missing does not depend on any of the missing or observed data. Although MCAR is convenient, it is very restrictive and generally unrealistic, so datasets with missing values are often not MCAR in the real world (Van Buuren, 2018, ch. 2.2.4).</p>
</div>
<div id="mar" class="section level4 unnumbered">
<h4>Missing at Random (MAR)</h4>
<p>MAR is the second missing data mechanism. MAR occurs when the probability a given variable is missing depends on available and observed information only (Gelman &amp; Hill, 2017, pg. 530). MAR is a weaker and more general classification of missingness than MCAR (Allison, 2012). The missing data model associated with MAR is defined as:</p>
<p><span class="math display">\[P(R=0|Y_{obs},Y_{mis},\psi) = P(R=0|Y_{obs},\psi)\]</span></p>
<p>For MAR, the missing data model reduces because the probability of data being missing depends on the missing data model and the observed data only. Therefore, <span class="math inline">\(Y_{mis}\)</span> does not affect the probability of missingness under MAR.</p>
<p>In the case of the weigh scale, MAR describes missing data that arises from the scale’s placement on hard or soft surfaces. If information about the surface (hard or soft) is fully observed for each attempted weight measurement, the probability of missing measurements then depends on available data - surface type - and thus falls under MAR (Van Buuren, 2018, ch. 1.2). Since MAR is a more general assumption than MCAR, it is more realistic to encounter in real-world datasets.</p>
</div>
<div id="mnar" class="section level4 unnumbered">
<h4>Missing Not at Random (MNAR)</h4>
<p>Missing not at random (MNAR) is the final missing data mechanism. MNAR suggests data’s “probability of being missing varies for reasons that are unknown to us” (Van Buuren, 2018, ch. 1.2). As a result, the missing data model for MNAR does not reduce:</p>
<p><span class="math display">\[P(R=0|Y_{obs},Y_{mis},\psi)\]</span></p>
<p>Missing data under MNAR may depend on observed and unobserved data, so the missing data model does not simplify at all. There are two major sub-categories that capture “unobserved” within MNAR. First, missingness may depend on the actual missing values themselves (Gelman &amp; Hill, 2017, pg. 530). When the weight of an object itself is to blame for a scale’s failure to report measurements, the underlying process falls under this sub-category of MNAR because the probability of weight being missing is related to weight itself (Van Buuren, 2018, ch. 1.2). The second type of MNAR covers missingness that depends on unobserved measurements or latent variables (Gelman &amp; Hill, 2017, pg. 530). The weigh scale example proposes three reasons a scale may generate missing measurements. These reasons do not cover countless other possibilities for why missing data may occur, such as the brand or age of a given scale. If the brand or age of a scale contributes to the probability of missing measurements but data is not available regarding a scale’s brand or age, then the missing data mechanism falls under the second sub-category of MNAR.</p>
</div>
</div>
<div id="background-ignorability" class="section level3 unnumbered">
<h3>Ignorability</h3>
<p>The missing data mechanism underpins the assumptions one can make when handling missing data. The most important assumption is that of <strong>ignorability</strong>. Missingness is ignorable “if it is missing at random and the probability of a missingness does not depend on the missing information itself” (Introduction to SAS, 2017). Therefore, the missingness within a dataset is said to be ignorable if the underlying missing data mechanism is MCAR or MAR. MNAR, on the other hand, constitutes missingness that is non-ignorable.</p>
<p>As Van Buuren notes, “the concept of ignorability plays an important role in the construction of imputation models” (2018, ch. 2.2.6). Specifically, ignorability determines whether one can ignore the way in which data are missing prior to imputing missing data through an imputation model (Nakagawa, 2015, Pg. 85). As stated in Introduction to SAS, “the assumption of ignorability is needed for optimal estimation of missing information and is a required assumption” (2017).</p>
<p>To formalize the statements above, consider the general expression for an imputation model:</p>
<p><span class="math display">\[P(Y_{mis}|Y_{obs}, R)\]</span></p>
<p>This expression means that the distribution of the missing data depends on the distribution of the observed data <span class="math inline">\(Y_{obs}\)</span> and the process that generated the missing data, <span class="math inline">\(R\)</span> (Van Buuren, 2018, ch 2.2.6). In the context of imputation, this expression suggests that the imputed values are generated conditional on the observed data and missing data mechanism.</p>
<p>If the missingness is ingorable, then:</p>
<p><span class="math display">\[P(Y|Y_{obs}, R=1) = P(Y|Y_{obs}, R=0)\]</span></p>
<p>This equality states that the distribution of the data <span class="math inline">\(Y\)</span> is the same for both the response (observed) and non-response (missing) groups (Van Buuren, 2018, ch 2.2.6). Essentially, this equation suggests that imputation models need not consider the missing data model when creating imputations for <span class="math inline">\(Y_{mis}\)</span>. As a result, the parameters of the missing data model, <span class="math inline">\(\psi\)</span>, are not important if the underlying missing data mechanism is ignorable.</p>
<p>The importance of this equality becomes clear through an example. Take the weigh scale experiment introduced in the beginning of the <a href="background.html#background">Background section</a>. Assume <span class="math inline">\(Y_{weight}\)</span> contains weight measurements in <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Y_{surface}\)</span> specifies the surface (hard or soft) of the scale generating weight measurements.</p>
<p>The researcher can model weight using the observed data only within each surface:</p>
<p><span class="math display">\[P(Y_{weight}|Y_{surface}=hard, R=1) ; P(Y_{weight}|Y_{surface}=soft, R=1)\]</span></p>
<p>If the missing data mechanism is ignorable, then:</p>
<p><span class="math display">\[P(Y_{weight}|Y_{surface}=hard, R=1) = P(Y_{weight}|Y_{surface}=hard, R=0)\]</span> <span class="math display">\[P(Y_{weight}|Y_{surface}=soft, R=1) = P(Y_{weight}|Y_{surface}=soft, R=0)\]</span></p>
<p>Therefore, the researcher can draw imputations for weight conditional on observed data only; he or she does not need to consider the missing data model within each subgroup, because the distribution for the observed and the missing data is the same (Van Buuren, 2018, ch. 2.2.6). Thus, the researcher can focus on the impact of the scale surface alone, as missing values for weight come from the same distribution as the observed.</p>
<p>If within each surface group the distribution for missing weights depends further on the actual mass of the object weighed, then the researcher cannot ignore the missing data model, because imputed values drawn from the observed data would be systematically different than the distribution of imputed values drawn when taking the missing data model into consideration. In this example, if weight were missing for objects that had a higher weight, imputations drawn from the observed data would systematically understate the weight of the missing objects regardless of the surface of the scale if the missing data model is ignored. The resulting imputations would be (potentially severly) biased depending on how influential the missing data model actually is.</p>
<p>Therefore, the implications of ignorability are of utmost importance when building an imputation model. Most imputation models in literature assume that the missing data mechanism is ignorable. Imputation models relying on this assumption produced unbiased imputations if the assumption of ignorability holds. In the event that it does not hold, imputations may be systematically biased.</p>
<p>The imputation models introduced in subsequent sections operate under the assumption that the missing data mechanism is ignorable (MCAR or MAR). The important takeaway, however, is that the researcher considers the missing data mechanism responsible for generating missing data and understands the effect of the missing data model on an imputation model’s ability to generate unbiased imputations. If the practicioner is aware of the potential consequences that stem from the missing data mechansim at hand, he or she is prepared to assess the benefits and drawbacks of each imputation model applied to a given dataset.</p>
<p>This section establishes a firm understanding of the concepts related to missing data and their implications. For an extended examination, consult Appendix C. Next, the authors review popular imputation models in literature and those supported in the <code>Autoimpute</code> package. All the models assume ignorability, so methods for non-ignorable missingness are out of scope. For interested readers, many studies cover non-ignorable missingness and its impact on the models presented in this research. <strong>(ADD SOURCES HERE TO REFER TO)</strong>.</p>
</div>
</div>
<div id="background-missing-data-methods" class="section level2 unnumbered">
<h2>Missing Data Methods</h2>
<p>Missing data mechanisms that satisfy ignorability provide the foundation for the missing data methods explored throughout the rest of this research. With an understanding of these concepts, one can now examine the imputation methods built upon these assumptions as well as the effect of those methods on supervised analysis.</p>
<p>Before the authors examine missing data methods, they clarify some terminology upfront to avoid confusion later on:</p>
<ul>
<li>A <strong>missing data method</strong> is a strategy to handle missing data. The two types of methods are deletion and imputation.</li>
<li>An <strong>imputation model</strong> is a strategy used to impute missing data. Imputation models are missing data methods within the imputation category.</li>
<li>An <strong>analysis model</strong> is a machine learning model that a researcher wants to apply to an underlying dataset. Because analysis models require complete data, the practicioner must perform either deletion or imputation to enable an analyis model to run.</li>
</ul>
<p>The sections below define and explore deletion and imputation models. In doing so, the authors reference the effect a given missing data method may have when subsequent analysis is performed. That being said, the researchers devote an entire section to analysis models after a full review of missing data methods.</p>
<div id="background-deletion" class="section level3 unnumbered">
<h3>Deletion</h3>
<p>One of the most popular missing data methods that data practitioners use when dealing with missing data is listwise deletion or complete-case analysis (CCA). Listwise deletion discards all rows in which at least one value in the columnspace of <span class="math inline">\(Y\)</span> is missing for a given record (Van Buuren, 2018, ch. 1.3.1). Complete-case analysis (CCA) is relatively easy to implement and enables analysis models to run without the need for imputation because missing data has been removed. However, CCA also has its flaws. As Gelman &amp; Hill (2017) describe, two problems arise with CCA:</p>
<ol style="list-style-type: decimal">
<li>If the units with missing values differ systematically from the completely observed cases, this could bias the complete-case analysis.</li>
<li>If many variables are included in a model, there may be very few complete cases, so that most of the data would be discarded for the sake of a simple analysis. (p. 531)</li>
</ol>
<p>The first hypothetical results from the strong assumptions listwise deletion makes regarding the missing data mechansim. CCA requies missing data to not only be ignorable but also MCAR in most cases. Therefore, listwise deletion can result in biased estimates even if ignorability holds but MAR is not met (Introduction to SAS, 2017).</p>
<p>The second hypothetical addresses the impact of removing observations from a dataset. Removing records from a dataset can drastically reduce the sample size if enough records have missing data. Small sample sizes can cause problems in parameter inference from supervised machine learning model analysis. Smaller samples reduce statistical power and, as a result, inflate the standard error of analysis model coefficients. If standard error increases enough, coefficients may become statistically insignificant in an analysis model (Introduction to SAS, 2017).</p>
</div>
<div id="background-imputation" class="section level3 unnumbered">
<h3>Imputation</h3>
<p>Because of these problems, researchers are cautious with listwise deletion and employ CCA as a benchmark or in specific cases where the effect from deletion is negligible. Instead, researchers turn to imputation in most cases to handle missing data. UNECE provides the following definition: “Imputation is a procedure for entering a value for a specific data item where the response is missing or unusable” (2000). Instead of discarding data, imputation retains potentially important information in the data by substituting missing values with plausible ones produced from an imputation model.</p>
<p>While this process seems straightforward, numerous imputation models exist and range from quite simple methods to very complex models. Furthermore, no universal evaluation metric exists to judge the accuracy or success of an imputation technique because the performance of an imputation model is often contextual, depending on the nature of the missing data beyond the missing data mechanism. Because of these reasons, practitioners must fully understand the different imputation options available to them and perform imputation analysis to discern which method serves their use case to best meet their objectives. The next section explores the fundamentals behind different imputation methods and examines their respective strengths and weaknesses.</p>
<p>In general, there are two major categories of imputation methods - <strong>univariate</strong> and <strong>multivariate</strong>.</p>
<div id="univariate" class="section level4 unnumbered">
<h4>Univariate</h4>
<p>Univariate imputation techniques focus on a single incomplete variable known as the target variable (Van Buuren, 2018, ch. 3). Univariate methods utilize observed values in the target variable to determine how to fill in missing values in the same target. Mean imputation is a popular example of a univariate method. When applied, mean imputation takes the mean of the observed features within a target variable and imputes missing values with the mean. This imputation method extends to any descriptive statistic that one can calculate from a single target variable’s observed data. Additional examples include median and mode imputation, which follow a similar process but use a different statistic for imputation.</p>
<p>Univariate measures do not have to impute a single static value. For example, linear interpolation employs linear curve fitting to construct imputations for missing values between two observed data points. Therefore, imputations from linear interpolation depend upon the closest observed values, so the value of an imputation will differ from one section of the data to another.</p>
<p>The only requirement for univariate methods is that they use information contained within the observed values of the same variable they are designed to impute. Appendix D goes into greater detail of all the univariate methods that the researchers support in <code>Autoimpute</code>.</p>
</div>
<div id="multivariate" class="section level4 unnumbered">
<h4>Multivariate</h4>
<p>The second major category of imputation methods is multivariate imputation. Multivariate imputation methods rely on one or more available features to predict plausible imputations for the target variable. When an imputation model has access to multiple features within a dataset, the method can preserve the relationships between the features and the target variable (Van Buuren, 2018, ch. 4.1). While this preservation is beneficial, it is not always clear which features one should use in a multivariate imputation model. In this case, the <strong>missing data pattern</strong> becomes useful to know. Van Buuren (2018) states:</p>
<blockquote>
<p>The missing data pattern influences the amount of information that can be transferred between variables. Imputation can be more precise if other variables are non-missing for those cases that are to be imputed. The reverse is also true. Predictors are potentially more powerful if they have are non-missing in rows that are vastly incomplete. (ch. 4.1.2)</p>
</blockquote>
<p>Since the missing data pattern shows how information can be transferred between variables, we can now calculate quantitative statistics to determine further how each variable connects to one another. Van Buuren (2018) names the first of these statistics <strong>Influx</strong>. The influx coefficient <span class="math inline">\(I_j\)</span> is defined as:</p>
<p><span class="math display">\[I_j = \frac{\sum_j^p\sum_k^p\sum_i^n (1-r_{ij})r_{ik}}{\sum_k^p\sum_i^n r_{ik}}\]</span></p>
<p>Influx represents the number of variable pairs (<span class="math inline">\(Y_j\)</span>,<span class="math inline">\(Y_k\)</span>) with <span class="math inline">\(Y_j\)</span> missing and <span class="math inline">\(Y_k\)</span> observed, divided by the total number of observed data points. Its value depends on the proportion of missing data of the variable, where <span class="math inline">\(I_j=0\)</span> when a variable is completely observed and <span class="math inline">\(I_j=1\)</span> when a variable is completely missing (Van Buuren, 2018, ch. 4.1.3). As Van Buuren notes, “for two variables with the same proportion of missing data, the variable with higher influx is better connected to the observed data, and might thus be easier to impute” (2018, ch. 4.1.3). Thus, influx is an important statistic that suggests which variables in the dataset are good candidates to be imputed using the other variables as predictors.</p>
<p>Van Buuren (2018) coins a similar coefficient of interest, named <strong>Outflux</strong>. The outflux coefficient <span class="math inline">\(O_j\)</span> is defined as:</p>
<p><span class="math display">\[O_j = \frac{\sum_j^p\sum_k^p\sum_i^n r_{ij}(1-r_{ik})}{\sum_k^p\sum_i^n 1-r_{ij}}\]</span> The outflux coefficient <span class="math inline">\(O_j\)</span> is the number of variable pairs with (<span class="math inline">\(Y_j\)</span>,<span class="math inline">\(Y_k\)</span>) with <span class="math inline">\(Y_j\)</span> observed and <span class="math inline">\(Y_k\)</span> missing, divided by the total number of incomplete data points. Its value indicates the potential usefulness of <span class="math inline">\(Y_j\)</span> for imputing other variables. As with influx, outflux depends on the proportion of missing data of the variable. Unlike influx, <span class="math inline">\(O_j=1\)</span> when a variable is completely observed, and <span class="math inline">\(O_j=0\)</span> when a variable is completely missing (Van Buuren, 2018, ch. 4.1.3). Van Buuren describes outflux in a similar manner to influx: “For two variables having the same proportion of missing data, the variable with higher outflux is better connected to the missing data, and thus potentially more useful for imputing other variables” (ch. 4.1.3). Accordingly, outflux recommends variables that are potentially more useful as predictors when imputing missing value variables in a multivariate missing dataset.</p>
<p>Practitioners use the above statistics to understand the importance of and relationships between variables that contain missing values. Once the set of variables is identified, a multivariate imputation model can be specified, and predictions from that model impute missing values in a target variable. A few examples of multivariate imputation methods are:</p>
<ul>
<li>Linear and Logistic Regression Imputation</li>
<li>Stochastic Regression Imputation</li>
<li>Bayesian Regression Imputation</li>
<li>Predictive Mean Matching (PMM)</li>
<li>Local Residual Draws (LRD)</li>
</ul>
<p>Appendix E provides more information regarding multivariate imputation methods available in <code>Autoimpute</code> and detail behind how each method works under the hood. <code>Autoimpute</code> implements regressions as seen in Van Buuren and implements PMM and LRD as seen in Morris et. al.</p>
</div>
</div>
</div>
<div id="background-single-imputation" class="section level2 unnumbered">
<h2>Single Imputation</h2>
<p>Each of the imputation methods presented above replaces missing values in dataset with imputed ones. As a result, the imputed dataset is complete, containing no missing values for any observation <span class="math inline">\(Y_{ij}\)</span> within <span class="math inline">\(Y\)</span>. As Gelman &amp; Hill note, “these methods keep the full sample size, which can be advantageous for bias and precision” (2017, pg. 532). In comparison to list-wise deletion, imputation methods do not discard any data; rather, they impute missing records so that no information is lost within the original dataset. As a result, statistical power is not reduced and standard errors are not inflated because the dataset retains the full sample size. That being said, these imputation methods can yield a different set of biases on their own when used via <strong>single imputation</strong>.</p>
<p>Single imputation is a process by which the researcher deploys imputation methods columnwise for each column with missing data and imputes respective missing values one time for each column. While the dataset is now complete, its use within analysis models can yield standard errors for parameter coefficients that tend to be too low (Gelman &amp; Hill, 2017, pg. 532). Gelman expands upon the issues with single imputation:</p>
<blockquote>
<p>The intuition here is that we have substantial uncertainty about the missing values, but by choosing a single imputation we in essence pretend that we know the true value with certainty.</p>
</blockquote>
<p>Each imputed value is actually a random variable that comes from a distribution of possible imputed values produced by the imputation model. When a researcher imputes a dataset using one draw from each imputed value’s distribution, then the researcher replaces missing values in a dataset with point estimates. Those point estimates become, in essence, true values - indistinguishable from the originally observed variables. As a result, the imputations stemming from single imputation ignore the variability and uncertainty regarding what the true value of the missing value actually is (Gelman &amp; Hill, 2017, pg. 532). An analysis model will treat observed and imputed values the same - as true values with no inherent variability.</p>
<p>Donald Rubin (as cited in Van Buuren, 2018, ch. 2) notes:</p>
<blockquote>
<p>Imputing one value for a missing datum cannot be correct in general, because we don’t know what value to impute with certainty (if we did, it wouldn’t be missing).</p>
</blockquote>
<p>Therefore, producing a single imputation for each missing value places too much trust in the imputed values themselves and disregards the variability stemming from the imputation process. As a result, practioners turn to another framework with which they impute missing data - <strong>multiple imputation</strong></p>
</div>
<div id="background-multiple-imputation" class="section level2 unnumbered">
<h2>Multiple Imputation</h2>
<p>As noted in the Introduction to SAS (2017):</p>
<blockquote>
<p>Multiple imputation is essentially an iterative form of stochastic imputation. However, instead of filling in a single value, the distribution of the observed data is used to estimate multiple values that reflect the uncertainty around the true value. These values are then used in the analysis of interest, such as in a OLS model, and the results combined. Each imputed value includes a random component whose magnitude reflects the extent to which other variables in the imputation model cannot predict it’s true values (Johnson and Young, 2011; White et al, 2010). Thus, building into the imputed values a level of uncertainty around the “truthfulness” of the imputed values.</p>
</blockquote>
<p>Specifically, multiple imputation includes three major steps in developing a multiply imputed datasets (Allison, 2012):</p>
<ol style="list-style-type: decimal">
<li>Introduce random variation into the process of imputing missing values, and generate several data sets, each with slightly different imputed values.</li>
<li>Perform an analysis on each of the data sets using the analysis model one would have used had the dataset been complete.</li>
<li>Combine the results into a single set of parameter estimates, standard errors, and test statistics using parameter pooling techniques.</li>
</ol>
<p>Figure 1 below visualizes the workflow described in the three steps above (Van Buuren, 2018, ch. 1.4.1).</p>
<div class="figure" style="text-align: center"><span id="fig:mutlipleimputationworkflow"></span>
<img src="figure/multiple-imputation-workflow.jpg" alt="Multiple Imputation Workflow" width="400px" />
<p class="caption">
Figure .: Multiple Imputation Workflow
</p>
</div>
<p>In multiple imputation, practitioners should choose an imputation method that can produce sufficient variation for the imputed value. Then multiple imputation results in multiple copies of imputed datasets with different imputed values. When performing analysis on multiply imputed data, each imputed dataset is analyzed separately and then parameters from those analyses are pooled together to get combined diagnostics on the performance of the multiple imputation process and the specified imputation model. This method “solves the standard error problem by calculating the variance of each parameter estimate across the several data sets” (Allison, 2012). The pooled parameters replace those from the supervised machine learning model of interest. The pooled parameters not only produce the coefficient estimate but also the properly account for the increase in standard error due to uncertainty introduced from imputing missing data.</p>
<p>The authors cover the analysis on multiply imputed data at the end of this section. Before then, the authors focus on the differences between single and multiple imputation in the context of imputation alone.</p>
</div>
<div id="background-example" class="section level2 unnumbered">
<h2>Single Imputation vs. Multiple Imputation Revisited</h2>
<p>The example below helps visualize the inherent differences between the single and multiple imputation procedure. Imagine a subset of the complete data matrix <span class="math inline">\(Y\)</span> from the weigh scale experiment:</p>
<p><span class="math display">\[Y_{subset}=\begin{bmatrix}soft &amp; 60 \\ soft &amp; NaN \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; NaN \end{bmatrix}\]</span></p>
<p>Further, assume the underlying missing data mechanism is ignorable, so imputation focuses on the observed dataset only. From the matrix above, one can discern that the distibution of weight depends on the surface of the scale. In this example, <span class="math inline">\(P(Y_{weight}|Y_{surface}=soft)\)</span> ~ <span class="math inline">\(N(60, 5)\)</span>, and <span class="math inline">\(P(Y_{weight}|Y_{surface}=soft)\)</span> ~ <span class="math inline">\(N(90, 5)\)</span>. The figure below visualizes the differences in the distribution of weight, conditional on the surface of the scale.</p>
<div class="figure" style="text-align: center"><span id="fig:scale-distribution"></span>
<img src="figure/scale-distribution.jpg" alt="Distribution of Weight by Scale Surface" width="400px" />
<p class="caption">
Figure .: Distribution of Weight by Scale Surface
</p>
</div>
<p>Now proceed with imputation analysis using single imputation. Assume that the imputation models takes a random draw from each respective surface’s weight distribution to impute missing data. Then the complete matrix becomes:</p>
<p><span class="math display">\[Y_{mis}=\begin{bmatrix}soft &amp; 60 \\ soft &amp; NaN \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; NaN \end{bmatrix} \rightarrow Y_{complete}=\begin{bmatrix}soft &amp; 60 \\ soft &amp; 63 \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; 91 \end{bmatrix}\]</span></p>
<p>The imputation model imputed 63 for <span class="math inline">\(Y_{2,2}\)</span> and 91 for <span class="math inline">\(Y_{6,2}\)</span>. Under single imputation, the matrix is now complete, as values for weight have been imputed. But an analysis model has access to the complete data matrix only, so it would not be able to distinguish which values were imputed and which were originally observed. Therefore, an analysis model treats the imputed values (63, 91) the same as observed values. The imputed values carry no uncertainty with them into the analysis phase.</p>
<p>Under multiple imputation, where <span class="math inline">\(m=3\)</span> representing 3 imputations, the matrices may look like the below:</p>
<p><span class="math display">\[Y_{mis}=\begin{bmatrix}soft &amp; 60 \\ soft &amp; NaN \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; NaN \end{bmatrix} \rightarrow Y_{complete}=\begin{bmatrix}soft &amp; 60 \\ soft &amp; 63 \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; 91 \end{bmatrix}, \begin{bmatrix}soft &amp; 60 \\ soft &amp; 66 \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; 89 \end{bmatrix},
\begin{bmatrix}soft &amp; 60 \\ soft &amp; 59 \\ soft &amp; 65 \\ hard &amp; 85 \\ hard &amp; 90 \\ hard &amp; 94 \end{bmatrix}\]</span></p>
<p>Multiple imputation produced 3 datasets. Across each imputation, the observed have the same values, which makes sense given that the true value of these weights is known. The imputed values, however, are different. The differences reflect the uncertainty about the nature of the true value imputed, given that the true value is actually missing. Single imputation disregards this inherent variability, which tricks analysis models into believing that the imputed values are true observations. Multiple imputation retains the variability introduced by the imputation process. This research covers analysis of multiply imputed data in the next section, as there is some additional work supervised learning methods must perform under multiple imputation. That being said, it’s important to take away the purpose of multiple imputation. It not only retains the full sample size but also retains the variability produced from the process of imputing missing data.</p>
</div>
<div id="background-analysis" class="section level2 unnumbered">
<h2>Analysis Models</h2>
<p>The primary purpose of handling missing data is to enable analysis models to run. As previously noted, most supervised maching learning models require datasets to be complete in order to fit an analysis model capable of making predictions or classifications. The previous sections in the background address the main points a researcher must consider when dealing with missing data. All of these considerations factor into the effect that the handling of missing data has on the results produced from an analysis model. One must remember that listwise deletion and imputation methods fundamentally alter a dataset. If the structure of the data is distorted in the process, the consequences affect inference derived from analysis models fit on imputed data. This section addresses the impact of imputation and listwise deletion from the perspective of analysis. It also covers the additional work necessary to fit analysis models on multiply imputed data.</p>
<p>In this research, an analysis model is nothing more than a supervised machine learning methods. This text restricts focus to linear and logistic regression. Both techniques operate under the assumption that the underlying dataset is complete, containing no missing records. As a result, analysis models do not have any information regarding what happened to the dataset before the model is fit. They cannot separate imputed values from true observations, and they do not know if records were removed through list-wise deletion prior to analysis. Therefore, the inference from the analysis model depends on the way in which missing data is handled.</p>
<div id="background-analysis-listwise" class="section level3 unnumbered">
<h3>Analysis after Listwise Deletion</h3>
<p>In the <a href="background.html#background-deletion">Deletion section</a>, the authors explain the potential pitfalls associated with listwise deletion. Depending on the proportion of missing data, listwise deletion may significantly deplete the sample size on which an analysis model is trained. In doing so, an analysis model generates larger standard errors for parameters estimates than it would had the dataset retained every record in othe original sample. As a result, the significance of coefficients may be called into question. Additionally, if the missing data mechanism is not MCAR, listwise deletion may discard records which contain important information. Doing so may lead to biased coefficient estimates in addition to increased standard errors of those estimates.</p>
</div>
<div id="background-analysis-single" class="section level3 unnumbered">
<h3>Analysis after Single Imputation</h3>
<p>In the <a href="background.html#background-single-imputation">Single Imputation section</a>, the authors note that single imputation retains the full dataset but ignores any uncertainty or variation introduced when imputing missing values. Therefore, an analysis model such as linear regression treats the single-imputed dataset as if each observation is a true value. The analysis model fits the dataset as it would any other dataset.</p>
<p>In the best case, if the imputation model used to impute data is not misspecified, then the the coefficients produced from the analysis model should at least be unbiased estimates of the true parameters had the dataset been fully observed. In the worst case, the imputation model used to impute data is misspecified, and the imputed values do not accurately reflect the distribution of the missing data. In this case, the analysis model produces coefficients that may be biased depending on the severity of the imputation model’s impact. In either situation, the standard error of the estimates produced from the analysis model will be too low (Gelman &amp; Hill, 2017, pg. 532). When the standard error of a parameter estimate is too low, the test-statistic for that parameter will be too high, and the statistical significance of the parameter may be inflated.</p>
<p>Underestimated standard errors may lead a researcher to erroneously conclude that statistical relationships exist. Such inference is dangerous and undermines the reason why missing data must be handled in the first place. Even if the researcher understands the missing data mechanism and applies a proper imputation model to handle missing data, he or she may not have done enough to properly account for the uncertainty introduced from imputation. That lack of consideration appears downstream, affecting the ability for the researcher to trust the significance of analysis model parameters.</p>
</div>
<div id="background-analysis-multiple" class="section level3 unnumbered">
<h3>Analysis after Multiple Imputation</h3>
<p>To handle the problems incurred from single imputation, this research suggests researchers employ imputation methods using multiple imputation. Multiple imputation creates multiple instances of the same dataset, depending on the number of imputations specified. Each imputed dataset has the same values for the observed but different values for the imputations. These differences highlight the variability introduced by imputation methods since the true value of a missing observation is unknown.</p>
<p>While multiple imputation retains sample size and imputation variability, it complicates the process of analysis. Because multiple imputed datasets exist, the researcher cannot simply apply one model to the complete dataset. Insetad, the practicioner must apply the same supervised model independently to each imputed dataset and then pool the results of each analysis model to produce proper coefficient estimates and standard errors.</p>
<p>The authors introduce new notation to explain the pooling process used in multiple imputation. Again, the authors follow the notation outlined in Van Buuren. The notation in this section also appears in Appendix B.</p>
<p>Assume <span class="math inline">\(Q\)</span> is the population parameter of interest. In this context, <span class="math inline">\(Q\)</span> is a scalar for the <span class="math inline">\(\beta\)</span> coefficient from simple linear regression or a vector <span class="math inline">\(\vec{Q}\)</span> containing the <span class="math inline">\(\beta_1,...,\beta_p\)</span> coefficients from multiple linear regression. (Note the same notation applies to coefficients from other regression models, such as logistic regression). In either case, <span class="math inline">\(\hat{Q}\)</span> is the estimate of <span class="math inline">\(Q\)</span>. <span class="math inline">\(U\)</span> represents the variance of scalar <span class="math inline">\(Q\)</span> or the covariance matrix of <span class="math inline">\(\vec{Q}\)</span> (Van Buuren, 2018, ch. 2.3.).</p>
<p>In the case of complete data or single imputation, the researcher fits an analysis model and produces the estimate <span class="math inline">\(\hat{Q}\)</span>. But when the researcher uses multiple imputation, the researcher must apply the analysis model to each imputed datset independently. Therefore, the researcher ends up with <span class="math inline">\(m\)</span> x <span class="math inline">\(\hat{Q}\)</span> estimates and <span class="math inline">\(m\)</span> x <span class="math inline">\(U\)</span> covariance matrices, one set from each analysis model applied to <span class="math inline">\(m\)</span> imputed datasets (Van Buuren, 2018, ch. 2.3). The researcher must pool these parameters together to build one analysis model that properly accounts for the estimates from each <span class="math inline">\(m\)</span> imputed dataset.</p>
<p>Pooling the coefficient estimate is the most straightforward. The equation is as follows:</p>
<p><span class="math display">\[\bar Q = \frac{1}{m}\sum_{\ell=1}^m \hat Q_\ell\]</span> In this equation, <span class="math inline">\(\bar Q\)</span> is the average of the <span class="math inline">\(\hat Q\)</span> estimates from each of the <span class="math inline">\(m\)</span> imputed datasets. This equation reduces the coefficients from each imputed dataset down to one estimate (or vector of coefficients) by taking the average across the <span class="math inline">\(m\)</span> imputed datasets. The resulting value is the pooled parameter estimate for the analysis model on multiply imputed data.</p>
<p>Pooling variance is more involved. The researcher must account for the variance from the analysis model of each imputed dataset. Additionally, the researcher must account for the variance that occurs between <span class="math inline">\(U\)</span> from each analysis model. Lastly, the researcher must add extra variance to account for the fact that only <span class="math inline">\(m\)</span> imputations were performed.</p>
<p>The first formula is the variance within:</p>
<p><span class="math display">\[ \bar U = \frac{1}{m}\sum_{\ell=1}^m \bar U_\ell\]</span> This formula is called <strong>variance within</strong>. As with the coefficient estimate, variance within is the average of the variance within each of the analysis models fit on the <span class="math inline">\(m\)</span> imputed datasets. It is the traditional variance metric one would expect from a linear regression, expect in the case of multiple imputation, it is the average across the <span class="math inline">\(m\)</span> imputed datasets (Van Buuren, 2018, ch 2.3).</p>
<p>The next formula is the variance between:</p>
<p><span class="math display">\[B = \frac{1}{m-1}\sum_{\ell=1}^m (\hat Q_\ell-\bar Q)(\hat Q_\ell-\bar Q)&#39;\]</span> This equation is called <strong>variance between</strong>. Because each of the <span class="math inline">\(m\)</span> imputed datasets produces a separate set of estimates for <span class="math inline">\(\hat Q\)</span>, variance exists between the estimates of each imputed dataset. Therefore, the analysis must account for the variance that occurs between the different estimates each imputation procedure produces (Van Buuren, 2018, ch 2.3).</p>
<p>The final formula represents the total variance:</p>
<p><span class="math display">\[T = \bar U + B + B/m\]</span> This equation is the <strong>total variance</strong> for the pooled parameter estimate of <span class="math inline">\(\bar Q\)</span>. It adds the variance within to the variance beween to the additional variance from a finite number of imputations, <span class="math inline">\(m\)</span>. Note that as <span class="math inline">\(m \rightarrow \infty\)</span>, the last part of this equation goes to <span class="math inline">\(0\)</span>. But because one cannot perform an infinite number of imputations, additional variance must be added to account for the number of imputations the researcher conducts (Van Buuren, 2018, ch. 2.3).</p>
<p>Therefore, the analysis model for multiply imputed data is parameterized by <span class="math inline">\(\bar Q\)</span> and <span class="math inline">\(T\)</span>. These parameters pool each individual analysis model applied to <span class="math inline">\(m\)</span> imputed datasets and produce one analysis model that accurately measures the coefficient estimate and accounts for the variance that results from imputing data.</p>
<p>While the process is more involved, analysis of multiply imputed data fully captures the impact of missingness and the effect of imputation. The pooled parameters also provide insights into the efficiency and performance of the imputation process. For example, a large variance between metric indicates that the imputation model produces wildly different imputations for each dataset. Additional metrics and diagnostics to assess the efficiency of the imputation process appear in Appendix F. The authors also cover these diagnostics in the <a href="methodology.html#methodology">Methodology</a> and <a href="findings.html#findings">Findings</a> sections.</p>
</div>
</div>
<div id="background-missing-data-autoimpute" class="section level2 unnumbered">
<h2>Missing Data and Autoimpute</h2>
<p>This background explores the main concepts related to missing data and discusses what a researcher must consider before selecting which missing data method to use. The section then introduces numerous imputation methods, each of which operates with its own set of assumptions but all of which assume that the missing data mechanism is at least ignorable. This text then briefly examines the impact of imputation on supervised analysis and demonstrates how concepts from missing data can leak into the inference of an analysis model if missingness is not handled with care.</p>
<p>The <code>Autoimpute</code> package gives the end user the tools to step through the entire process of handling missing data to performing supervised analysis. The package includes methods to explore and visualize missing data to discern what missing data mechanisms may be present. The package also includes numerous imputation methods, which the practicioner can use within the package’s implementation of the Single Imputation and Multiple Imputation frameworks. Finally, <code>Autoimpute</code> extends linear and logistic regression to mulitply imputed datasets. In doing so, <code>Autoimpute</code> handles parameter pooling for the user and includes additional metrics and diagnostics to assess the impact of imputation on downstream analysis.</p>
<p>In the Methodology section, the authors return to the <code>Autoimpute</code> package itself and demonstrate how it is used to step through everything covered in the background section. In addition, the authors design experiments to dig deeper into the effect of specific imputation models and how they affect analysis depending on the nature of the missing data.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="methodology.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["capstone.pdf", "PDF"], ["capstone.epub", "EPUB"], ["capstone.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
