---
author: 'Shahid Barkat, Joseph Kearney'
date: 'June, 2019'
institution: 'University of Chicago'
division: 'Graham School'
advisor: 'Dr. Arnab Bose'
altadvisor: 'Dr. Sema Barlas'
department: 'Continuing Liberal and Professional Studies'
degree: 'Master of Science in Analytics'
title: 'Data Analytics as a Service (DAaaS): Automated & Intelligent Imputation Methods for Supervised Machine Learning'
knit: "bookdown::render_book"
site: bookdown::bookdown_site
header-includes:
  \usepackage{array}
  \usepackage{multirow}
  \usepackage{booktabs}
  \usepackage{colortbl}
  \usepackage{makecell}
  \usepackage{xcolor}
  \usepackage{tabu}
  \usepackage{amsmath}
output: 
#  phoenixdown::capstone_pdf: default
#  phoenixdown::capstone_gitbook: default
  phoenixdown::capstone_word: default
#  phoenixdown::capstone_epub: default
#
# If you are creating a PDF you'll need to write your preliminary content as well as define some other parameters below.
abstract: | 
  `r if(knitr:::is_latex_output()) paste(readLines("00--abstract.Rmd"), collapse = '\n  ')` 
executive: |  
  `r if(knitr:::is_latex_output()) paste(readLines("00--executive-summary.Rmd"), collapse = '\n  ')` 
#
# Longer preliminary content, like the Abstract and Executive Summary above, is best organized in seperate files.
# The inline r function is used above to paste the contents of those files, instead of requiring you one to type 
# lengthy text directly into the yaml header. For shorter messages, typing directly into the YAML is easier. See below.
# VERY IMPORTANT: A tab indent is needed on the line following the | .
#
#preface: |
#  A preface is OPTIONAL. Use a preface if you want to explain your interest in the report topic and include anything about your #experience that readers should keep in mind. If you would rather not include a preface, comment it out or delete it from the YAML #header of the index.Rmd file.
#
#acknowledgements: |
#  I want to thank a few people.
#dedication: |
#  You can have a dedication here if you wish.
#
# Download your specific bibliography database file, place it in the "bib" folder, and refer to it in the line below
bibliography: bib/thesis.bib
#
# To change your Citation Style Language file, you can do so below. Though the default is apa style.
csl: csl/apa.csl
lot: true
lof: true
#
# Add a "#" at the beginning of the following line if you'd like remove space between parapgraphs.
space_between_paragraphs: true
#
# Dimensions below correspond to University of Chicago Masters of Science in Analytics requirements.
geometry: "left=3.8cm, right=2.5cm, top=2.5cm, bottom=2.5cm"
#
  #header-includes:
#- \usepackage{tikz}
---



<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Preface for example, simply delete lines 32-33 above or add a "#"" before them to comment out.  If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this:
-->

<!--

If you receive a duplicate label error after knitting, delete the extra .Rmd file and then knit again.
-->

<!-- You'll need to include the order that you'd like Rmd files to appear in the _bookdown.yml file for PDF files and also delete the # before rmd_files: there. Do not include 00(two-hyphens)prelim.Rmd,  00(two-hyphens)abstract.Rmd and 00(two-hyphens)executive summary.Rmdsince they are handled in the YAML above differently for the PDF version.
-->

<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers on chapters, which is the standard for each section.
-->

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
```

# Introduction {.unnumbered}

The researchers develop and maintain an open-source, Python-based package named `Autoimpute` to address one of the most common nuisances in machine learning – datasets with missing values. The package implements numerous imputation algorithms and extends common supervised machine learning methods to handle multiply imputed datasets. `Autoimpute` treats missing data as a first-class citizen in the Python world, making imputation familiar to Python developers and easy to use for those new to the language. Ultimately, the package provides users an end-to-end framework that covers missing data exploration to imputation analysis.

## Problem Statement {.unnumbered}

Machine learning models rely entirely on the data they are provided, and most require that the underlying dataset be complete. In reality, however, many real-world datasets are incomplete, containing missing values for the response variable and one or more of the features collected. As a result, the machine learning practitioner must decide what to do about missing data. The way in which the practitioner handles missing data greatly affects the interpretability of and results from the machine learning models the practitioner builds and deploys.

The challenge of handling missing data has inspired numerous imputation methods, each of which has its advantages and disadvantages depending on the nature of the missing data and the machine learning task at hand. Unfortunately, the existence of multiple imputation methods does not get the machine learning practitioner any closer to handling missing data. First, imputation methods can be challenging to understand and computationally expensive to implement. Next, no global criteria or metric exists to select the optimal imputation method given a dataset with missing values. Even if a practitioner successfully implements imputation methods, he or she has no structured way to evaluate how well imputation performs or how imputation affects supervised models downstream built upon imputed data.

Because handling missing data is quite complex, most statistical packages simply remove records with missing data so that machine learning models can execute. While this option is simple to implement and enables models to run, it generally comes with numerous undesirable side effects if data is not missing completely at random (MCAR). This subject is explored further in the background section of this paper. However, in practice, real-world data is rarely MCAR, so models should generally avoid discarding missing records. Extensions in software packages do exist to implement imputation methods automatically. That being said, the practitioner still must decide which method to implement, explain why an imputation method is optimal, and evaluate how the optimal imputation method affects models trained on imputed data.

## Research Purpose {.unnumbered}

This research aids the machine learning practitioner by bringing more clarity to the imputation process, making imputation methods more accessible and comparable, and measuring the impact imputation methods have in supervised regression and classification models. This research strives to not just automate imputation but also develop an open-source framework to structure and evaluate imputation methods within a supervised machine learning process.

To address this purpose, this research specifies four objectives:

1. Assess the extent of the missing data problem with descriptive and visual measures
2. Examine the factors related to the missingness of data
3. Deploy imputation methods and select the most appropriate methodology
4. Measure the impact of imputation to the fit, stability, bias, and variance of parameters derived from supervised models built on imputed data

The researchers meet these objectives by developing an open-source Python package that can generalize across cross-sectional and time-series datasets. Any data science professional can deploy or reuse components of the package itself. Eventually, the researchers will accept contributions from the open source community as well.







<!--chapter:end:index.Rmd-->

<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called background.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from 01-background.Rmd.
-->

<!--
The {#background} text after the chapter declaration will allow us to link throughout the document back to the beginning of of the background section.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# Background {#background .unnumbered}

One must understand what missingness is and why it exists before deciding how to handle it. The authors explore the nature of missingness using a motivating example. 

For an experiment, assume that a random sample of measurements is collected from thousands of weigh scales. Also assume each weigh scale in the experiment may fail to produce measurements for three separate reasons. First, a scale might run out of batteries, in which case all measurements from that scale cease for a given period of time. Next, a scale may fail more frequently for heavier objects or items over a certain weight threshhold. And finally, a scale may stop reporting measurements when placed on a soft surface instead of a hard one (van Buuren, 2018, ch. 1.2). 

As a result of these scenarios, the random sample collected likely has many instances in which weight measurements are unobserved. How missingness in this sample is handled moving forward will depend on characteristics of the missing data itself and the process that generated missingess. The authors devote the rest of this section to concepts related to the nature of missingness and how it is handled. The authors refer back to this example to make concepts more concrete.

## Basic Terminology and Notation {#background-basic-terms .unnumbered}

Before diving into concepts related to missingness, the authors establish notation used throughout this text. The authors use this notation to develop mathematical expressions that explain these concepts succinctly. This research follows the notation van Buuren uses in the second edition of his book, Flexible Imputation of Missing Data. For more information, refer to Appendix B, which collects and summarizes the notation seen throughout this research. Appendix C contains the equations and expressions that formalize concepts related to missing data, while Appendix D contains the definitions for the concepts themselves.

In the introductory example, weigh scales produce a set of $n$ measurements, some of which may be missing weight. $Y$ denotes the $n$ x $p$ matrix that contains the $n$ measurements and the $p$ variables recorded along with the measurements. The surface of the scale (hard or soft) is an example of a discrete variable in $p$, while the weight measurement itself is a continuous variable in $p$. We can retrieve an observation within $Y$ by specifying the row and column index corresponding to the observation's cell. To do so, we use the notation $y_{ij}$, where $i$ represents the row and $j$ represents the column associated with a scalar $y$ in matrix $Y$. 

$Y$ itself represents the hypothetically complete data (van Buuren, 2018, ch. 2.2.3), which is comprised of $Y_{obs}$ and $Y_{mis}$. $Y_{obs}$ represents each row $Y_i$ out of $n$ records that have known values for each column $Y_j$ in $p$. $Y_{mis}$, on the other hand, contains records with missing observations across any of the columns in $p$. Note that $Y = (Y_{obs}, Y_{mis})$. The hypothetically complete data equals the conjoined observed and missing data matrices.

It is convenient to store whether or not a cell in $Y$ is missing in a separate matrix $R$. Therefore, $R$ is an $n$ by $p$ matrix where all entries $r_{ij} \in {0, 1}$. Any observation $r_{ij}=1$ corresponds to a known value for $y_{ij}$. On the contrary, any observation $r_{ij}=0$ corresponds to a missing value for $y_{ij}$. $R$ is commonly referred to as the **missing indicator matrix**, while $Y$ is the **complete data matrix** (van Buuren, 2018, ch. 2.2.3).

## Missing Data Mechanism {#background-missing-data-mech  .unnumbered} 

Each of the three scenarios discussed above causes a given weigh scale to produce missing data, but the underlying reason for missingness is quite different in each case. Donald Rubin describes the ways in which data can be missing (Rubin, 1976). According to Rubin (as cited in van Buuren, 2018, ch. 1.2), every observation in a dataset has some probability of being missing. The process that governs these probabilities is called the **missing data mechanism** (Rubin, as cited in van Buuren, 2018, ch. 1.2). The missing data mechanism generates a statistical relationship between observations and the probability of missing data (Nakagawa, 2015, p. 83). The **missing data model** is the function that formalizes that statistical relationship (van Buuren, 2018, ch. 2.2.4). These statistical relationships fall into one of three categories, each of which represents a different missing data mechanism (Rubin, as cited in van Buuren, 2018, ch. 1.2).

The general expression for the missing data model is defined as: 

$$P(R|Y_{obs}, Y_{mis},\psi)$$

$\psi$ contains the parameters of the missing data model. This expression notes that the probability of missingness $P(R=0)$ within a dataset depends on the observed data, the missing data, and the missing data model's parameters (van Buuren, 2018, ch. 2.2.4). From another lense, this expession states that the missing data model is the distribution of the missingness indicator conditional on the observed data, the missing data, and the parameters of the missing data model. 

The missing data model is the function that formalizes the statistical relationship governed by a missing data mechanism. The next section examines the manifestation of the missing data model under each mechanism.

### MCAR, MAR, and MNAR {#background-mcar-mar-mnar .unnumbered} 

Rubin popularized names for the three categories that represent the main missing data mechanisms:

* **Missing Completely at Random (MCAR)**
* **Missing at Random (MAR)**
* **Missing Not at Random (MNAR)**

In this research, the authors refer to each category by its abbreviated label. The subsections below examine each category in more detail.

#### Missing Completely at Random (MCAR) {#mcar .unnumbered}

MCAR is the first of the three missing data mechanisms. MCAR assumes missing values in the underlying dataset have the same probability of missingness for all cases (Gelman & Hill, 2017, p. 530). Thus, MCAR implies that the probability of missingness within a dataset is completely unrelated to the data in question or any other observed or unobserved data. The missing data model 
associated with MCAR is defined as:

$$P(R=0|Y_{obs},Y_{mis},\psi) = P(R=0|\psi)$$

Note that the general expression of the missing data model reduces to a much simpler form. Under MCAR, the probability of data being missing depends on the parameters of the missing data only and not on the values of missing data itself or the value of any of the observed data (van Buuren, 2018, ch. 2.2.4).

From the weigh scale example, MCAR governs the probability of values being missing from a scale that runs out of batteries at some point in time (van Buuren, 2018, ch. 1.2). For simplicity, assume time is not a latent variable nor of interest in the data collection process. In this case then, the missing values produced from the scale do not depend on the weight of the object in question nor the surface used for the scale, so the probability a value is missing does not depend on any of the missing or observed data. Although MCAR is convenient, it is very restrictive and generally unrealistic, so datasets with missing values are often not MCAR in the real world (van Buuren, 2018, ch. 2.2.4).

#### Missing at Random (MAR) {#mar .unnumbered}

MAR is the second missing data mechanism. MAR occurs when the probability a given variable is missing depends on available and observed information only (Gelman & Hill, 2017, p. 530). MAR is a weaker and more general classification of missingness than MCAR (Allison, 2012). The missing data model associated with MAR is defined as:

$$P(R=0|Y_{obs},Y_{mis},\psi) = P(R=0|Y_{obs},\psi)$$

For MAR, the missing data model reduces because the probability of data being missing depends on the missing data model and the observed data only. Therefore, $Y_{mis}$ does not affect the probability of missingness under MAR.

In the case of the weigh scale, MAR describes missing data that arises from the scale’s placement on hard or soft surfaces. If information about the surface (hard or soft) is fully observed for each attempted weight measurement, the probability of missing measurements then depends on available data - surface type - and thus falls under MAR  (van Buuren, 2018, ch. 1.2). Since MAR is a more general assumption than MCAR, it is more realistic to encounter in real-world datasets. 

#### Missing Not at Random (MNAR) {#mnar .unnumbered}

Missing not at random (MNAR) is the final missing data mechanism. MNAR suggests data’s “probability of being missing varies for reasons that are unknown to us” (van Buuren, 2018, ch. 1.2). As a result, the missing data model for MNAR does not reduce:

$$P(R=0|Y_{obs},Y_{mis},\psi)$$

Missing data under MNAR may depend on observed and unobserved data, so the missing data model does not simplify at all. There are two major sub-categories that capture "unobserved" within MNAR. First, missingness may depend on the actual missing values themselves (Gelman & Hill, 2017, p. 530). When the weight of an object itself is to blame for a scale’s failure to report measurements, the underlying process falls under this sub-category of MNAR because the probability of weight being missing is related to weight itself (van Buuren, 2018, ch. 1.2). The second type of MNAR covers missingness that depends on unobserved measurements or latent variables (Gelman & Hill, 2017, p. 530). The weigh scale example proposes three reasons a scale may generate missing measurements. These reasons do not cover countless other possibilities for why missing data may occur, such as the brand or age of a given scale. If the brand or age of a scale contributes to the probability of missing measurements but data is not available regarding a scale's brand or age, then the missing data mechanism falls under the second sub-category of MNAR. 

### Ignorability {#background-ignorability .unnumbered}

The missing data mechanism underpins the assumptions one can make when handling missing data. The most important assumption is that of **ignorability**. Missingness is ignorable “if it is missing at random and the probability of a missingness does not depend on the missing information itself” (Multiple Imputation in Stata, 2017). Therefore, the missingness within a dataset is said to be ignorable if the underlying missing data mechanism is MCAR or MAR. MNAR, on the other hand, constitutes missingness that is non-ignorable.

As van Buuren notes, "the concept of ignorability plays an important role in the construction of imputation models" (2018, ch. 2.2.6). Specifically, ignorability determines whether one can ignore the way in which data are missing prior to imputing missing data through an imputation model (Nakagawa, 2015, p. 85). As stated in Multiple Imputation in Stata, “the assumption of ignorability is needed for optimal estimation of missing information and is a required assumption” (2017).

To formalize the statements above, consider the general expression for an imputation model:

$$P(Y_{mis}|Y_{obs}, R)$$

An imputation model must find plausible values for $Y_{mis}$ that respect its distribution. In the general case, the distribution of the missing data depends on the distribution of the observed data $Y_{obs}$ and the process that generated the missing data, $R$ (van Buuren, 2018, ch 2.2.6). In the context of imputation, this expression suggests that the imputed values are generated conditional on the observed data and missing data mechanism.

If the missingness is ignorable, then:

$$P(Y|Y_{obs}, R=1) = P(Y|Y_{obs}, R=0)$$

This equality states that the distribution of the data $Y$ is the same for both the response (observed) and non-response (missing) groups (van Buuren, 2018, ch 2.2.6). Essentially, this equation suggests that imputation models need not consider the missing data model when creating imputations for $Y_{mis}$. As a result, the parameters of the missing data model, $\psi$, are not important if the underlying missing data mechanism is ignorable.

The importance of this equality becomes clear through an example. Take the weigh scale experiment introduced in the beginning of the [Background section](#background). Assume $Y_{weight}$ contains weight measurements in $Y$, and $Y_{surface}$ specifies the surface (hard or soft) of the scale generating weight measurements. 

The researcher can model weight using the observed data only within each surface: 

$$P(Y_{weight}|Y_{surface}=hard, R=1) ; P(Y_{weight}|Y_{surface}=soft, R=1)$$ 

If the missing data mechanism is ignorable, then:

$$P(Y_{weight}|Y_{surface}=hard, R=1) = P(Y_{weight}|Y_{surface}=hard, R=0)$$ 
$$P(Y_{weight}|Y_{surface}=soft, R=1) = P(Y_{weight}|Y_{surface}=soft, R=0)$$

Therefore, the researcher can draw imputations for weight conditional on observed data only; he or she does not need to consider the missing data model within each subgroup, because the distribution for the observed and the missing data is the same (van Buuren, 2018, ch. 2.2.6). Thus, the researcher can focus on the impact of the scale surface alone, as missing values for weight within a surface come from the same distribution as the observed.

If within each surface group the distribution for missing weights depends further on the actual mass of the object weighed, then the researcher cannot ignore the missing data model. In this case, imputed values drawn from the observed data would be systematically different than the distribution of imputed values drawn when taking the missing data model into consideration. In this example, if weight were missing for objects that had a higher weight, imputations drawn from the observed data would systematically understate the weight of the missing objects regardless of the surface of the scale if the missing data model is ignored. The resulting imputations would be (potentially severly) biased depending on how influential the missing data model actually is (van Buuren, 2018, ch. 2.2.6).

Therefore, the implications of ignorability are of utmost importance when building an imputation model. Most imputation models in literature assume that the missing data mechanism is ignorable. Imputation models relying on this assumption produce unbiased imputations if the assumption of ignorability holds. In the event that it does not hold, imputations may be systematically biased in most cases.

The imputation models introduced in subsequent sections operate under the assumption that ignorability holds. Some of the imputation models require the even stricter MCAR mechanism, although the authors devote more time to imputation models that work under MAR. The important takeaway, however, is that the researcher considers the missing data mechanism responsible for generating missing data and understands the effect of the missing data model on an imputation model's ability to generate plausible imputations. If the practicioner is aware of the potential consequences that stem from the missing data mechansim at hand, he or she is prepared to assess the benefits and drawbacks of each imputation model applied to a given dataset.

This section establishes a firm understanding of the concepts related to missing data and their implications. Next, the authors review popular imputation models in literature and those supported in the `Autoimpute` package. All the models assume ignorability, so methods for non-ignorable missingness are out of scope. For interested readers, many studies cover non-ignorable missingness and its impact on the models presented in this research. To explore non-ignorable missingness in more detail, see (Xie, et. al, 2018; Lu & Zhang, 2013; Yin & Shi, 2015).

## Missing Data Patterns {#background-missing-data-patterns .unnumbered}

The missing data mechanism describes the process that governs the relationship between observed values and probability of missingness, while the missing data model formalizes the statistical relationship behind this process. These concepts cover the nature of missingness, but they do not describe the patterns of missingness that exist within a dataset. **Missing data patterns** describe the characteristics of missingness within a dataset. There are many characteristics that detail how data is missing. For example, a multivariate dataset could have data missing in one or multiple variables. In addition, the proportion of missingness could vary for each variable with missing data. One feature may have 10% of its observations missing while another is unobserved 90% of the time.

While missing data patterns are distinct from missing data mechanisms, the missing data pattern may augment or undermine the importance of the missing data mechanism and how it is handled using missing data methods. The authors introduce the concept because missing data patterns reappear throughout the text, specifically in the [Methodology section](#methodology). That being said, missing data patterns are not the primary focus of this research, so the authors keep this section brief. For more information on missing data patterns, refer to van Buuren's book, *Flexible Imputation of Missing Data*.

## Missing Data Methods {#background-missing-data-methods .unnumbered} 

Missing data mechanisms that satisfy ignorability provide the foundation for the missing data methods explored throughout the rest of this research. With an understanding of these concepts, one can now examine the imputation methods built upon these assumptions as well as the effect of those methods on supervised analysis.

Before the authors examine missing data methods, they clarify some terminology upfront to avoid confusion later on:

* A **missing data method** is a strategy to handle missing data. The two types of methods are deletion and imputation.
* **Deletion** is a strategy to handle missing data. Deletion represents the first class of missing data methods that handle missing values.
* An **imputation model** is a strategy used to impute missing data. Imputation represents the second class of missing data methods that handle missing values.
* Imputation models can be either **univariate** or **multivariate** depending on how they go about imputing missing data.
* An **analysis model** is a machine learning model that a researcher wants to apply to an underlying dataset. Because analysis models require complete data, the practicioner must perform either deletion or imputation to enable an analyis model to run.

The sections below define and explore deletion and imputation models. In doing so, the authors reference the effect a given missing data method may have when subsequent analysis is performed. That being said, the researchers devote an entire section to analysis models after a full review of missing data methods.

### Deletion {#background-deletion .unnumbered}

One of the most popular missing data methods that data practitioners use when dealing with missing data is listwise deletion or complete-case analysis (CCA). Listwise deletion discards all rows in which at least one value in the columnspace of $Y$ is missing for a given record (van Buuren, 2018, ch. 1.3.1). Complete-case analysis (CCA) is relatively easy to implement and enables analysis models to run without the need for imputation because missing data has been removed. However, CCA also has its flaws. As Gelman & Hill (2017) describe, two problems arise with CCA:

1. If the units with missing values differ systematically from the completely observed cases, this could bias the complete-case analysis.
2. If many variables are included in a model, there may be very few complete cases, so that most of the data would be discarded for the sake of a simple analysis. (p. 531)

The first hypothetical results from the strong assumptions listwise deletion makes regarding the missing data mechansim. CCA requies missing data to not only be ignorable but also MCAR in most cases. Therefore, listwise deletion can result in biased estimates even if ignorability holds but MAR is not met (Multiple Imputation in Stata, 2017).

The second hypothetical addresses the impact of removing observations from a dataset. Removing records from a dataset can drastically reduce the sample size if enough records have missing data. Small sample sizes can cause problems in parameter inference from supervised machine learning model analysis. (Dong & Peng, 2013). Smaller samples reduce statistical power and, as a result, inflate the standard error of analysis model coefficients. If standard error increases enough, coefficients may become statistically insignificant in an analysis model (Multiple Imputation in Stata, 2017).

### Imputation {#background-imputation .unnumbered}

Because of these problems, researchers are cautious with listwise deletion and employ CCA as a benchmark or in specific cases where the effect from deletion is negligible. Instead, researchers turn to imputation in most cases to handle missing data. In their *Glossary of Terms for Statistical Editing*, the United Nations Statistical Commission and the Economic Council for Europe provides the following definition: “Imputation is a procedure for entering a value for a specific data item where the response is missing or unusable” (2000). Instead of discarding data, imputation retains potentially important information in the data by substituting missing values with plausible ones produced from an imputation model.

While this process seems straightforward, numerous imputation models exist and range from quite simple methods to very complex models. Furthermore, no universal evaluation metric exists to judge the accuracy or success of an imputation technique because the performance of an imputation model is often contextual, depending on the nature of the missing data beyond the missing data mechanism. Because of these reasons, practitioners must fully understand the different imputation options available to them and perform imputation analysis to discern which method serves their use case to best meet their objectives. The next section explores the fundamentals behind different imputation methods and examines their respective strengths and weaknesses. 

In general, there are two branches of imputation methods - **univariate** and **multivariate**.

#### Univariate {#univariate .unnumbered}

Univariate imputation techniques focus on a single incomplete variable known as the target variable (van Buuren, 2018, ch. 3). Univariate methods utilize observed values in the target variable to determine how to fill in missing values in the same target. Mean imputation is a popular example of a univariate method. When applied, mean imputation takes the mean of the observed features within a target variable and imputes missing values with the mean. This imputation method extends to any descriptive statistic that one can calculate from a single target variable’s observed data. Additional examples include median and mode imputation, which follow a similar process but use a different statistic for imputation.

Univariate measures do not have to impute a single static value. For example, linear interpolation employs linear curve fitting to construct imputations for missing values between two observed data points. Therefore, imputations from linear interpolation depend upon the closest observed values, so the value of an imputation will differ from one section of the data to another. Similarly, one can structure a normal distribution (or any distribution for that matter) using parameters determined from the observed data and then impute missing values using random draws from the specified distribution. This idea extends to the multivariate case, in which one samples from a joint distribution - a topic covered in the multivariate section.

The only requirement for univariate methods is that they use information contained within the observed values of the same variable they are designed to impute. Appendix E goes into greater detail of all the univariate methods that the researchers support in `Autoimpute`. 

#### Multivariate {#multivariate .unnumbered}

The second major category of imputation methods is multivariate imputation. Multivariate imputation methods rely on one or more available features to predict plausible imputations for the target variable. When an imputation model has access to multiple features within a dataset, the method can preserve the relationships between the features and the target variable (van Buuren, 2018, ch. 4.1). While this preservation is beneficial, it is not always clear which features one should use in a multivariate imputation model. In this case, the **missing data pattern** becomes useful to know. van Buuren (2018) states:

> The missing data pattern influences the amount of information that can be transferred between variables. Imputation can be more precise if other variables are non-missing for those cases that are to be imputed. The reverse is also true. Predictors are potentially more powerful if they have are non-missing in rows that are vastly incomplete. (ch. 4.1.2)

Since the missing data pattern shows how information can be transferred between variables, we can now calculate quantitative statistics to determine further how each variable connects to one another. van Buuren (2018) names the first of these statistics **Influx**. The influx coefficient $I_j$ is defined as:

$$I_j = \frac{\sum_j^p\sum_k^p\sum_i^n (1-r_{ij})r_{ik}}{\sum_k^p\sum_i^n r_{ik}}$$

Influx represents the number of variable pairs ($Y_j$,$Y_k$) with $Y_j$ missing and $Y_k$ observed, divided by the total number of observed data points. Its value depends on the proportion of missing data of the variable, where $I_j=0$ when a variable is completely observed and $I_j=1$ when a variable is completely missing (van Buuren, 2018, ch. 4.1.3). As van Buuren notes, "for two variables with the same proportion of missing data, the variable with higher influx is better connected to the observed data, and might thus be easier to impute" (2018, ch. 4.1.3). Thus, influx is an important statistic that suggests which variables in the dataset are good candidates to be imputed using the other variables as predictors.

van Buuren (2018) coins a similar coefficient of interest, named **Outflux**. The outflux coefficient $O_j$ is defined as:

$$O_j = \frac{\sum_j^p\sum_k^p\sum_i^n r_{ij}(1-r_{ik})}{\sum_k^p\sum_i^n 1-r_{ij}}$$
The outflux coefficient $O_j$ is the number of variable pairs with ($Y_j$,$Y_k$) with $Y_j$ observed and $Y_k$ missing, divided by the total number of incomplete data points. Its value indicates the potential usefulness of $Y_j$ for imputing other variables. As with influx, outflux depends on the proportion of missing data of the variable. Unlike influx, $O_j=1$ when a variable is completely observed, and $O_j=0$ when a variable is completely missing (van Buuren, 2018, ch. 4.1.3). van Buuren describes outflux in a similar manner to influx: "For two variables having the same proportion of missing data, the variable with higher outflux is better connected to the missing data, and thus potentially more useful for imputing other variables" (ch. 4.1.3). Accordingly, outflux recommends variables that are potentially more useful as predictors when imputing missing value variables in a multivariate missing dataset. 

Practitioners can use the above statistics to understand the importance of and relationships between variables that contain missing values. Once the set of variables is identified, a multivariate imputation model can be specified, and predictions from that model impute missing values in a target variable. A few examples of multivariate imputation methods are:

* Linear and Logistic Regression Imputation
* Stochastic Regression Imputation
* Bayesian Regression Imputation
* Predictive Mean Matching (PMM)
* Local Residual Draws (LRD)

Appendix F provides more information regarding multivariate imputation methods available in `Autoimpute` and detail behind how each method works under the hood. `Autoimpute` implements regressions as seen in van Buuren and implements PMM and LRD as seen in Morris et. al.

The univariate and multivariate imputation methods presented above replace missing values in dataset with imputed ones. As a result, the imputed dataset is complete, containing no missing values for any observation $Y_{ij}$ within $Y$. As Gelman & Hill note, "these methods keep the full sample size, which can be advantageous for bias and precision" (2017, p. 532). In comparison to listwise deletion, imputation methods do not discard any data; rather, they impute missing records so that no information is lost within the original dataset. As a result, statistical power is not reduced and standard errors are not inflated because the dataset retains the full sample size. That being said, these imputation methods can yield a different set of biases on their own. Furthermore, these imputation methods impute missing values only once. Imputing via **single imputation** may not do enough to accurately account for the variance introduced from imputation. 

## Single Imputation {#background-single-imputation .unnumbered}

Single imputation is a process by which the researcher deploys imputation methods columnwise for each column with missing data and imputes respective missing values one time for each column. While the dataset is now complete, its use within analysis models can yield standard errors for parameter coefficients that tend to be too low (Gelman & Hill, 2017, p. 532). Gelman expands upon the issues with single imputation:

> The intuition here is that we have substantial uncertainty about the missing values, but by choosing a single imputation we in essence pretend that we know the true value with certainty.

Each imputed value is actually a random variable that comes from a distribution of possible imputed values produced by the imputation model. When a researcher imputes a dataset using one draw from each imputed value's distribution, then the researcher replaces missing values in a dataset with point estimates. Those point estimates become, in essence, true values - indistinguishable from the originally observed variables. As a result, the imputations stemming from single imputation ignore the variability and uncertainty regarding what the true value of the missing value actually is (Gelman & Hill, 2017, p. 532). An analysis model will treat observed and imputed values the same - as true values with no inherent variability.

Donald Rubin (as cited in van Buuren, 2018, ch. 2) notes: 

> Imputing one value for a missing datum cannot be correct in general, because we don’t know what value to impute with certainty (if we did, it wouldn’t be missing).

Therefore, producing a single imputation for each missing value places too much trust in the imputed values themselves and disregards the variability stemming from the imputation process. As a result, practioners turn to another framework with which they impute missing data - **multiple imputation**

## Multiple Imputation {#background-multiple-imputation .unnumbered} 

As noted in the Multiple Imputation in Stata (2017):

> Multiple imputation is essentially an iterative form of stochastic imputation. However, instead of filling in a single value, the distribution of the observed data is used to estimate multiple values that reflect the uncertainty around the true value. These values are then used in the analysis of interest, such as in a OLS model, and the results combined. Each imputed value includes a random component whose magnitude reflects the extent to which other variables in the imputation model cannot predict it’s true values (Johnson and Young, 2011; White et al, 2010). Thus, building into the imputed values a level of uncertainty around the “truthfulness” of the imputed values.

Specifically, multiple imputation includes three major steps in developing a multiply imputed datasets (Allison, 2012):

1. Introduce random variation into the process of imputing missing values, and generate several data sets, each with slightly different imputed values.
2. Perform an analysis on each of the data sets using the analysis model one would have used had the dataset been complete.
3. Combine the results into a single set of parameter estimates, standard errors, and test statistics using parameter pooling techniques.

Figure 1 below visualizes the workflow described in the three steps above (van Buuren, 2018, ch. 1.4.1).

```{r mutlipleimputationworkflow, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Multiple Imputation Workflow"}
include_graphics(path = "figure/multiple-imputation-workflow.jpg")
```

In multiple imputation, practitioners should choose an imputation method that can produce sufficient variation for the imputed value between each run. Then multiple imputation results in multiple copies of imputed datasets with different imputed values. When performing analysis on multiply imputed data, each imputed dataset is analyzed separately and then parameters from those analyses are pooled together to get combined diagnostics on the performance of the multiple imputation process and the specified imputation model (Vink). This method “solves the standard error problem by calculating the variance of each parameter estimate across the several data sets” (Allison, 2012). The pooled parameters replace those from the supervised machine learning model of interest. The pooled parameters not only produce the coefficient estimate but also the properly account for the increase in standard error due to uncertainty introduced from imputing missing data. 

The authors cover the analysis on multiply imputed data at the end of this section. First, the authors focus on the differences between single and multiple imputation in the context of imputation alone.

## Single Imputation vs. Multiple Imputation Revisited {#background-example .unnumbered}

The example below helps visualize the inherent differences between the single and multiple imputation procedure. Imagine a subset of the complete data matrix $Y$ from the weigh scale experiment:

$$Y_{subset}=\begin{bmatrix}soft & 60 \\ soft & NaN \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & NaN \end{bmatrix}$$

Further, assume the underlying missing data mechanism is ignorable, so imputation focuses on the observed dataset only. From the matrix above, one can discern that the distibution of weight depends on the surface of the scale. In this example, $P(Y_{weight}|Y_{surface}=soft)$ ~ $N(60, 5)$, and $P(Y_{weight}|Y_{surface}=soft)$ ~ $N(90, 5)$. The figure below visualizes the differences in the distribution of weight, conditional on the surface of the scale.

```{r scale-distribution, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Distribution of Weight by Scale Surface"}
include_graphics(path = "figure/scale-distribution.jpg")
```

Now proceed with imputation analysis using single imputation. Assume that the imputation models takes a random draw from each respective surface's weight distribution to impute missing data. Then the complete matrix becomes:

$$Y_{mis}=\begin{bmatrix}soft & 60 \\ soft & NaN \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & NaN \end{bmatrix} \rightarrow Y_{complete}=\begin{bmatrix}soft & 60 \\ soft & 63 \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & 91 \end{bmatrix}$$

The imputation model imputed 63 for $Y_{2,2}$ and 91 for $Y_{6,2}$. Under single imputation, the matrix is now complete, as values for weight have been imputed. But an analysis model has access to the complete data matrix only, so it would not be able to distinguish which values were imputed and which were originally observed. Therefore, an analysis model treats the imputed values (63, 91) the same as observed values. The imputed values carry no uncertainty with them into the analysis phase. 

Under multiple imputation, where $m=3$ representing 3 imputations, the matrices may look like the below:

$$Y_{mis}=\begin{bmatrix}soft & 60 \\ soft & NaN \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & NaN \end{bmatrix} \rightarrow Y_{complete}=\begin{bmatrix}soft & 60 \\ soft & 63 \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & 91 \end{bmatrix}, \begin{bmatrix}soft & 60 \\ soft & 66 \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & 89 \end{bmatrix},
\begin{bmatrix}soft & 60 \\ soft & 59 \\ soft & 65 \\ hard & 85 \\ hard & 90 \\ hard & 94 \end{bmatrix}$$

Multiple imputation produced 3 datasets. Across each imputation, the observed have the same values, which makes sense given that the true value of these weights is known. The imputed values, however, are different. The differences reflect the uncertainty about the nature of the true value imputed, given that the true value is actually missing. Single imputation disregards this inherent variability, which tricks analysis models into believing that the imputed values are true observations. Multiple imputation retains the variability introduced by the imputation process. This research covers analysis of multiply imputed data in the next section, as there is some additional work supervised learning methods must perform under multiple imputation. That being said, it's important to take away the purpose of multiple imputation. It not only retains the full sample size but also retains the variability produced from the process of imputing missing data.

## Analysis Models {#background-analysis .unnumbered}

The primary purpose of handling missing data is to enable analysis models to run. As previously noted, most supervised maching learning models require datasets to be complete in order to fit an analysis model capable of making predictions or classifications (Dong & Peng, 2013). The previous sections in the background address the main points a researcher must consider when dealing with missing data. These considerations influence the imputation model a researcher deploys to impute missing data. The results from the imputation model then affect the results produced from an analysis model run on imputed data.

One must remember that listwise deletion and imputation methods fundamentally alter a dataset. Therefore, the quality of the results produced from a missing data method depend on the degree to which the method is able to capture the nature of the missing data when modeling missing values (Vink). If the missing data method used is misspecified, the structure of the data after imputation is distorted, and this distortion affects inference derived from analysis models fit on the altered dataset. This section addresses the impact of listwise deletion and imputation from the perspective of analysis. It also covers the additional work necessary to fit analysis models on multiply imputed data. 

In this research, an analysis model is nothing more than a supervised machine learning method. This text focuses on linear and logistic regression. Both techniques operate under the assumption that the underlying dataset is complete, containing no missing records. As a result, analysis models do not have any information regarding what happened to the dataset before the model is fit. They cannot separate imputed values from true observations, and they do not know if records were removed through listwise deletion prior to analysis. Therefore, the inference from the analysis model depends on the way in which missing data is handled.

### Analysis after Listwise Deletion {#background-analysis-listwise .unnumbered}

In the [Deletion section](#background-deletion), the authors explain the potential pitfalls associated with listwise deletion. Depending on the proportion of missing data, listwise deletion may significantly deplete the sample size on which an analysis model is trained. In doing so, an analysis model generates larger standard errors for parameters' estimates than it would had the dataset retained every record in othe original sample. As a result, the significance of coefficients may be called into question. Additionally, if the missing data mechanism is not MCAR, listwise deletion may discard records which contain important information. Doing so may lead to biased coefficient estimates in addition to increased standard errors of those estimates (Dong & Peng, 2013).

While listwise deletion can cause problems downstream in analysis, there are cases in which the method is appropriate for handling missing data. Allison (2014) defends listwise deletion as a potentially optimal solution under certain missing data patterns. Four cases in which listwise deletion may outerperform more complex imputation methods include the following:

* The proportion of missingness is very low relative to proportion of observed, and the sample size is large enough where loss of power is negligible.
* The missing data mechanism is MCAR.
* In linear regression, the missing data occurs in the *predictor* variable only, regardless of the missing data mechanism, so long as the missingness does not depend on the *response* variable used in an analysis model.
* For logistic regression, the missing data occurs in the *response* variable only, regardless of the missing data mechanism, so long as the missingness does not depend on the *predictor* variables used in the analysis model.

Allison has proved that listwise deletion actually outerperforms other methods, producing unbiased estimates so long as the regression models are correctly specified and the criteria above are met (2014). That being said, the practicioner should still benchmark listwise deletion against other imputation methods, as the outcome from listwise deletion is intricately linked to the nature of the missingness in the specific dataset at hand.

### Analysis after Single Imputation {#background-analysis-single .unnumbered}

In the [Single Imputation section](#background-single-imputation), the authors note that single imputation retains the full dataset but ignores any uncertainty or variation introduced when imputing missing values. Therefore, an analysis model such as linear regression treats the single-imputed dataset as if each observation is a true value. The analysis model fits the dataset as it would any other dataset (van Buuren, 2018, ch. 2.1.2). 

In the best case, if the imputation model used to impute data is not misspecified, then the the coefficients produced from the analysis model should at least be unbiased estimates of the true parameters had the dataset been fully observed. In the worst case, the imputation model used to impute data is misspecified, and the imputed values do not accurately reflect the distribution of the missing data. In this case, the analysis model produces coefficients that may be biased depending on the severity of the imputation model's impact. In either situation, the standard error of the estimates produced from the analysis model will be too low (Gelman & Hill, 2017, p. 532). When the standard error of a parameter estimate is too low, the test-statistic for that parameter will be too high, and the statistical significance of the parameter may be inflated. 

Underestimated standard errors may lead a researcher to erroneously conclude that statistical relationships exist. Such inference is dangerous and undermines the reason why missing data must be handled in the first place. Even if the researcher understands the missing data mechanism and applies a proper imputation model to handle missing data, he or she may not have done enough to properly account for the uncertainty introduced from imputation. That lack of consideration appears downstream, affecting the ability for the researcher to trust the significance of parameters from analysis models.

### Analysis after Multiple Imputation {#background-analysis-multiple .unnumbered}

To handle the problems incurred from single imputation, the authors suggests researchers employ imputation methods using multiple imputation. Multiple imputation creates multiple instances of the same dataset, depending on the number of imputations specified. Each imputed dataset has the same values for the observed but different imputations for the missing values. These differences highlight the variability introduced by imputation methods since the true value of a missing observation is unknown (van Buuren, 2018, ch. 2.1.2).

While multiple imputation retains sample size and imputation variability, it complicates the process of analysis. Because multiple imputed datasets exist, the researcher cannot simply apply one model to the complete dataset. Instead, the practicioner must apply the same supervised model independently to each imputed dataset and then pool the results of each analysis model to produce proper coefficient estimates and standard errors.

The authors introduce new notation to explain the pooling process used in multiple imputation. Again, the authors follow the notation outlined in van Buuren. The notation in this section also appears in Appendix B, the expressions appear in Appendix C, and concepts appear in Appendix D.

Assume $Q$ is the population parameter of interest. In the context of analysis models, $Q$ is a scalar for the $\beta$ coefficient from simple linear regression or a vector $\vec{Q}$ containing the $\beta_1,...,\beta_p$ coefficients from multiple linear regression. (Note the same notation applies to coefficients from other regression models, such as logistic regression). In either case, $\hat{Q}$ is the estimate of $Q$. $U$ represents the variance of estimate $\hat Q$ or the covariance matrix of $\vec{\hat Q}$ (van Buuren, 2018, ch. 2.3.).

In the case of complete data or single imputation, the researcher fits an analysis model and produces the estimate $\hat{Q}$. But when the researcher uses multiple imputation, the researcher must apply the analysis model to each imputed datset independently. Therefore, the researcher ends up with $m$ x $\hat{Q}$ estimates and $m$ x $U$ covariance matrices, one set from each analysis model applied to $m$ imputed datasets (van Buuren, 2018, ch. 2.3). The researcher must pool these parameters together to build one analysis model that properly accounts for the estimates from each $m$ imputed dataset.

Pooling the coefficient estimate is the most straightforward. The equation is as follows:

$$\bar Q = \frac{1}{m}\sum_{\ell=1}^m \hat Q_\ell$$
In this equation, $\bar Q$ is the average of the $\hat Q$ estimates from each of the $m$ imputed datasets. This equation reduces the coefficients from each imputed dataset down to one estimate (or vector of coefficients) by taking the average across the $m$ imputed datasets. The resulting value is the pooled parameter estimate for the analysis model on multiply imputed data.

Pooling variance is more involved. The researcher must account for the variance from the analysis model of each imputed dataset. Additionally, the researcher must account for the variance that occurs between $U$ from each analysis model. Lastly, the researcher must add extra variance to account for the fact that only $m$ imputations were performed.

The first formula is the variance within:

$$ \bar U = \frac{1}{m}\sum_{\ell=1}^m \bar U_\ell$$
This formula is called **variance within**. As with the coefficient estimate, variance within is the average of the variance within each of the analysis models fit on the $m$ imputed datasets. It is the traditional variance metric one would expect from a linear regression, expect in the case of multiple imputation, it is the average across the $m$ imputed datasets (van Buuren, 2018, ch 2.3).

The next formula is the variance between:

$$B = \frac{1}{m-1}\sum_{\ell=1}^m (\hat Q_\ell-\bar Q)(\hat Q_\ell-\bar Q)'$$
This equation is called **variance between**. Because each of the $m$ imputed datasets produces a separate set of estimates for $\hat Q$, variance exists between the estimates of each imputed dataset. Therefore, the analysis must account for the variance that occurs between the different estimates each imputation procedure produces (van Buuren, 2018, ch 2.3).

The final formula represents the total variance:

$$T = \bar U + B + B/m$$
This equation is the **total variance** for the pooled parameter estimate of $\bar Q$. It adds the variance within to the variance beween to the additional variance from a finite number of imputations, $m$. Note that as $m \rightarrow \infty$, the last part of this equation goes to $0$. But because one cannot perform an infinite number of imputations, additional variance must be added to account for the number of imputations the researcher conducts (van Buuren, 2018, ch. 2.3).

Therefore, the analysis model for multiply imputed data is parameterized by $\bar Q$ and $T$. These parameters pool each individual analysis model applied to $m$ imputed datasets and produce one analysis model that accurately measures the coefficient estimate and accounts for the variance that results from imputing data.

While the process is more involved, analysis of multiply imputed data fully captures the impact of missingness and the effect of imputation. The pooled parameters also provide insights into the efficiency and performance of the imputation process. For example, a large variance between metric indicates that the imputation model produces wildly different imputations for each dataset. As a result, the analysis model produces largely different coefficient estimates, so the variance between them is high.

## Missing Data and Autoimpute {#background-missing-data-autoimpute .unnumbered}

This background explores the main concepts related to missing data and discusses what a researcher must consider before selecting which missing data method to use. The section then introduces numerous missing data methods, each of which operates with its own set of assumptions but all of which assume that the missing data mechanism is at least ignorable. This text then briefly examines the impact of deletion and imputation on supervised analysis and demonstrates how concepts from missing data can leak into the inference of an analysis model if missingness is not handled with care.

The `Autoimpute` package gives the end user the tools to step through the entire process of handling missing data to performing supervised analysis. The package includes methods to explore and visualize missing data to discern what missing data mechanisms may be present. The package also includes numerous imputation methods, which the practicioner can use within the package's implementation of the Single Imputation and Multiple Imputation frameworks. Finally, `Autoimpute` extends linear and logistic regression to mulitply imputed datasets. In doing so, `Autoimpute` handles parameter pooling and variance calculation for the user. It also includes additional metrics and diagnostics to assess the impact of imputation on downstream analysis. 

In the Methodology section, the authors return to the `Autoimpute` package itself and demonstrate how it is used to step through everything covered in the background section. In addition, the authors design experiments to dig deeper into the effect of specific imputation models and how they affect analysis depending on the nature of the missing data.

<!--chapter:end:01-background.Rmd-->

# Methodology {#methodology .unnumbered}

The missing data methods introduced in the background section are a subset of those available in `Autoimpute`. Beyond `Autoimpute` numerous additional missing data methods exist to handle missing data, and they are continuously being developed and improved (Schouten, et al, 2018). Therefore, it is vital to understand the circumstances under which each missing data method is effective, and it is important to evaluate each technique in relation to other methods (Schouten, et al, 2018). To do so, researchers can simulate complete datasets then introduce artificial missingness under different types of missing data mechanisms with different missing data patterns. Such a procedure affords the researcher an opportunity to evaluate missing data methods and their effect on analysis models under different circumstances (Schouten, et al, 2018).

## Assessing Missing Data Methods through Simulation {#methodology .unnumbered}

Schouten, et al. (2018) formalizes a step-by-step process in which a missing data methodology is evaluated by means of simulations:

1. Simulate a multivariate, complete dataset. The complete dataset becomes the population of interest and the source of truth.
2. Introduce arificial missingness to the complete dataset using missing data mechanisms and missing data patterns. This process results in an incomplete dataset. 
3. Use missing data methods to handle the missing data in the incomplete dataset.
4. Apply an analysis model and obtain statistical inference for the original, complete dataset as well as the incomplete dataset after dealing with the missing values. A comparison of these inferences gives an indication of the performance of the missing data method.

In this methodology, the authors follow the steps outlined above. The authors simulate a complete dataset using the `MASS` package in R (Venables & Ripley, 2002). The authors introduce missingness in a complete dataset using the `ampute` function from the `MICE` package in R (van Buuren & Groothuis-Oudshoorn, 2011). The `ampute` function can generate multivariate missing data within a complete dataset by defining a missing data mechanism (MCAR, MAR, MNAR) as well as missing data patterns, such as proportions of missingness and the features that should contain missingness (van Buuren & Groothuis-Oudshoorn, 2011). The authors use these R packages to produce complete and incomplete datasets, which cover steps 1 and 2 above.

Next, the authors use `Autoimpute` to cover steps 3 and 4. The authors explore the performance of imputation methods and their effect on analysis models under two separate circumstances. The authors begin by simulating a dataset with no missingness. A simple linear regression is performed on this simulated dataset and its parameters of interest are stored as benchmarks. Next, the researchers create artifical missingness in the complete dataset using two different types of missing data mechanisms with different missing data patterns. This procedure results in two disctinct, incomplete datasets. Each incomplete dataset will have different observations missing, but any observed values will be the same across the two incomplete datasets and the original complete dataset. 

The authors then impose the same deletion and impution methods on each of the incomplete datasets. In each example, the researchers first explore missingness patterns within the dataset. Then, the authors use the following missing data methods:

* Listwise deletion or CCA
* Mean imputation
* Least Squares imputation
* Predictive Mean Matching

Mean, least squares, and predictive mean matching are performed using the mutliple imputation framework. Listwise deletion is performed separately because it does not require single or multiple imputation. All methods are implemented using the `Autoimpute` package.

`Autoimpute` offers many more missing data methods, but these four are useful for this study because each carries a different set of assumptions and takes a very different approach to handling missing values. Listwise deletion is a deletion method, so it ignores missingness entirely by discarding records with any missing observations. Mean imputation is a univariate method, so it disregards any structure between the target variable and other features. Least squares is a supervised multivariate method that considers the structure of the data but ignores the uncertainty surrounding imputation. Finally, PMM is an advanced semi-supervised multivariate method that blends concepts from bayesian analysis, linear regression, and k-nearest neighbors. The sections below demonstrate when these methods work and when they do not. As always, their performance is directly linked to the missing data mechanism at hand and the nature of missingness within a dataset. Therefore, some methods shine in circumstances where other methods underperform.

## The Full Dataset {.unnumbered}

The authors use the MASS package (Venables & Ripley, 2002) to simulate the full dataset, or the source of truth. The full dataset contains 500 observations for feature $x$ and response $y$. The dataset is generated from a joint normal distribution, where $\mu_x=10$ and $\mu_y=5$. The correlation between $x$ and $y$ equals 0.7. At this point, no missingness exists in $x$ or $y$.

The figure below visualizes the distribution of each variable:

```{r fullsidebyside, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Distribution of Full x and y"}
include_graphics(path = "figure/full-side-by-side.jpg")
```

The next figure displays the joint relationship between $x$ and $y$. The figure plots the marginal distribution of each variable as well:

```{r full-joint, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals of Full x and y"}
include_graphics(path = "figure/full-joint.jpg")
```

Both plots come from native visualization methods in the `Autoimpute` package.

The full dataset does not contain any missing values, so no deletion or imputation is necessary before conducting analysis. Using `Autoimpute`, the researchers fit a linear regression model on the full dataset. The summary of the model fit appears below:

```{r full-regression, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results: Full"}
include_graphics(path = "figure/full-regression.jpg")
```

The results from linear regression on the full dataset serve as the golden source. The coefficient estimate for $x$ is 0.7. Using notation related to imputation analysis, this coefficient estimate of $x$ represents $\hat Q$ - the unbiased estimate of the population parameter of interest $Q$. Because there is only one predictor, the covariance matrix $U$ simply reduces to the variance of the estimate.

The summary output above displays diagnostics for the linear regression model. The output uses aliases for concepts covered in the [Background section](#background)

* `coefs` - The parameter estimate $\hat Q$
* `std` - The standard error of the coefficient estimate
* `vw` - The variance-within $\bar U$
* `vb` - The variance-between $B$
* `vt` - The total variance $T$

Observe that `vb`, or the variance-between, is equal to 0. This result occurs because no missingness exists and multiple imputation is not used. The variance-between becomes important in subsequent sections where missing data methods are used within the multiple imputation framework.

## Example 1: MCAR with Missingness in the Response {.unnumbered}

In the first example, the researchers generate MCAR missingness within the response, $y$. Response $y$ contains 40% missing values. Feature $x$ remains fully observed. The two plots below showcase how to use `Autoimpute` to explore missingness within a given dataset. `Autoimpute` leverages the excellent `missingno` Python package to explore missingness within datasets (Bilogur, 2018) prior to applying any missing data methods. The plots are quite simple in this case, but they can help detect patterns in missing data when multiple features are present with different levels of missingness.

```{r y-mis-forty-loc, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Missingness Locations, MCAR"}
include_graphics(path = "figure/y-mis-forty-loc.jpg")
```

```{r y-mis-forty-bar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Missingness Percentage, MCAR"}
include_graphics(path = "figure/y-mis-forty-bar.jpg")
```

Next, the researchers employ missing data methods to handle missing data in $y$. In this case, missing data methods must find plausible imputations for the 40% of $y$ that is missing. The imputation methods used include mean, linear regression, and pmm. The researchers also use listwise deletion, although there is no visualization within `Autoimpute` for complete-case analysis because no imputations are performed. For imputation methods, the researchers deploy each strategy within the multiple imputation framework. The number of imputations performed for each method is 5.

`Autoimpute` natively supports a number of visualization methods to assess the impact of imputation on incomplete datasets. 

The visualizations below show the impact of mean, linear regression, and pmm imputation. For each strategy, there are two respective plots. The first plot is the new scatterplot between $x$ and $y$ after imputation. It also includes the new marginal distributions for $x$ and $y$ after imputation. The second plot shows the imputations for $y$ comingled with observed values for $y$ for each of the 5 imputations performed in the multiple imputation framework. 

Let's start with mean imputation:

```{r multi-mean, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with Mean Imputation, MCAR"}
include_graphics(path = "figure/multi-mean.jpg")
```

```{r swarm-mean, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: Mean Imputation, MCAR"}
include_graphics(path = "figure/swarm-mean.jpg")
```

Note that for mean imputation, the imputations do not depend on the value of $x$, and the relationship between $y$ and $x$ is ignored. This result makes sense, as mean imputation is a univariate method. Also note that the imputation values in the swarm plot are the same for each imputation. This occurs because the mean of the observed values of $y$ do not change from imputation to imputation within the multiple imputation framework. Therefore, the imputation values within each imputed dataset are the same, and the imputation values across each imputed dataset are the same.

Next, observe imputation via least squares:

```{r multi-lm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with Least Squares Imputation, MCAR"}
include_graphics(path = "figure/multi-lm.jpg")
```

```{r swarm-lm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: Least Squares Imputation, MCAR"}
include_graphics(path = "figure/swarm-lm.jpg")
```

The plots for linear regression now take into account the relationship between $y$ and $x$. As a result, the imputed values are different within an imputed dataset but the same across imputed datasets. Within an incomplete dataset, the linear model produces different imputed values, which depend on the value of $x$. But across incomplete datasets, the linear model's imputed values are the same because the model is fit on the same observed data and no random error is added to imputations.

Finally, observe PMM imputation:

```{r multi-pmm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with PMM Imputation, MCAR"}
include_graphics(path = "figure/multi-pmm.jpg")
```

```{r swarm-pmm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: PMM Imputation, MCAR"}
include_graphics(path = "figure/swarm-pmm.jpg")
```

PMM Imputation respects not only the relationship between $y$ and $x$ but also the variance between the features. Imputations are no longer from the "line of best fit" as they are with least squares. Additionally, imputations are different within and across imputed datasets. Therefore, PMM does the best job at respecting the structure of the data and producing variability between and across imputed datasets to account for the uncertainty of the true value of a missing data point.

## Example 2: MAR with Missingness in the Predictor {.unnumbered}

In the second example, the researchers generate MAR missingness within the predictor, $x$. The missigness is right-tailed, which means that the probability that predictor $x$ is missing increases with the value of $y$. Predictor $x$ contains 40% missing values. Response $y$ remains fully observed.

The researchers take the same approach to Example 2 as they do to Example 1. First, the authors plot the missing data patterns within $x$ and $y$. Then, listwise deletion is performed, followed by multiple imputation for mean, least squares, and predictive mean matching. Again, the multiple imputation iterates 5 times.

The plots below demonstrate that missingness now occurs within the predictor $x$, while $y$ is fully observed.

```{r x-mis-forty-loc-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Missingness Locations, MAR"}
include_graphics(path = "figure/x-mis-forty-loc-mar.jpg")
```

```{r x-mis-forty-bar-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Missingness Percentage, MAR"}
include_graphics(path = "figure/x-mis-forty-bar-mar.jpg")
```

Next, the authors plot the scatterplot & marginals for each imputation method as well as the resulting swarm plot.

Starting with mean:

```{r multi-mean-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with Mean Imputation, MAR"}
include_graphics(path = "figure/multi-mean-mar.jpg")
```

```{r swarm-mean-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: Mean Imputation, MAR"}
include_graphics(path = "figure/swarm-mean-mar.jpg")
```

Now, mean imputations do not depend on the value of $y$. The relationship between $y$ and $x$ is still ignored. This result makes sense, as mean imputation is a univariate method. Also note that the imputation values in the swarm plot are the same for each imputation. This occurs because the mean of the observed values of $x$ do not change from imputation to imputation within the multiple imputation framework. Therefore, the imputation values within each imputed dataset are the same, and the imputation values across each imputed dataset are the same. Lastly, observe that mean imputation does not care which missing data mechanism is present because it considers only the target variable it imputes.

Then least squares:

```{r multi-lm-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with Least Squares Imputation, MAR"}
include_graphics(path = "figure/multi-lm-mar.jpg")
```

```{r swarm-lm-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: Least Squares Imputation, MAR"}
include_graphics(path = "figure/swarm-lm-mar.jpg")
```

The plots for linear regression still follow the logic explained from the plots in Example 1. That being said, the missing data mechanism now clearly affects the resulting imputations. Remember, the imputed values from linear regression come from the line of best fit of the imputation model. When the missing data mechanism changes and the missingness appears in predictor $x$, the slope of the line formed by the imputations is drastically different than it is in Example 1. This observation becomes important later on when the authors examine the effect of least squares imputation on analysis models from each example.

And finally PMM:

```{r multi-pmm-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Joint and Marginals with PMM Imputation, MAR"}
include_graphics(path = "figure/multi-pmm-mar.jpg")
```

```{r swarm-pmm-mar, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Swarm Plot: PMM Imputation, MAR"}
include_graphics(path = "figure/swarm-pmm-mar.jpg")
```

PMM also follows the logic explained from the plots in Example 1. But now, PMM takes into account the missing data mechanism at hand. Imputations for $x$ are more often larger values than smaller ones. This is because there are more missing values in $x$ for higher values of $y$, and $x$ and $y$ are positively correlated. Again, this observation becomes important later on when the authors examine the effect of PMM imputation on analysis models from each example.

## Analysis Models on each Example {.unnumbered}

The sections above take the user through the data exploration phase and multiple imputation phase of `Autoimpute`. At each step, the authors use visualization methods from the `Autoimpute` package to demonstrate what each imputation method does under the hood when used in the multiple imputation framework. The next section, [Findings](#findings), demonstrates how each imputation algorithm affects the inference derived from pooled coefficients of linear regression applied to multiply imputed data. Results from analysis on imputed datasets are compared to the results from analysis on the complete dataset.

<!--chapter:end:02-methodology.Rmd-->

# Findings {#findings .unnumbered}

## Full Model Recap {.unnumbered}

This section begins with a recap of linear regression on the full dataset. The results below serve as the benchmark for comparison and are considered the golden standard.

The results for the full model are displayed again:

```{r full-regression-again, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Recap: Full"}
include_graphics(path = "figure/full-regression.jpg")
```

Next, the authors examine whether the results from the missing data methods distort the results from linear regression on imputed data. If coefficients are biased, then the missing data method used does not properly respect the original structure of the complete data. Further, if variance measures are too narrow, then the missing data method does not create sufficient variability to account for uncertainty introduced by missingness, and the statistical significance of the coefficients may be called into question.

The authors display the results of linear regression for each example in the methodology section.

## Results from Example 1  {.unnumbered}
 
The authors review the results from linear regression fit to the multiply imputed data from Example 1. Recall that Example 1 contains 40% missingness in the response $y$, and the missingness mechanism is MCAR.

First, listwise delete:

```{r mcar-listwise-delete, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MCAR: Listwise Delete"}
include_graphics(path = "figure/mcar-listwise-delete.jpg")
```

Next, mean imputation:

```{r mcar-mean, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MCAR: Mean Imputation"}
include_graphics(path = "figure/mcar-mean.jpg")
```

Next, least squares imputation:

```{r mcar-ls, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MCAR: Least Squares Imputation"}
include_graphics(path = "figure/mcar-ls.jpg")
```

Finally, pmm imputation:

```{r mcar-pmm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MCAR: PMM Imputation"}
include_graphics(path = "figure/mcar-pmm.jpg")
```

## Findings from Example 1 {.unnumbered}

The authors explore the impact each missing data method has on the linear regression's coefficient estimate for $x$ and the resulting standard error and variance of $x$. 

First, the authors discuss coefficient estimates. Mean imputation produces a grossly biased parameter estimate for $x$. This result occurs because mean imputation thins the distribution of the variable it imputes. As a result, mean imputation shrinks the correlation between any feature and the imputed variable (van Buuren, ch. 1.3.1). When the imputed variable is the response in a linear regression, the resulting coefficient trends toward zero. Therefore, mean imputation is suboptimal in this case. 

Listwise deletion, least squares, and PMM all produce parameter estimates close to the true value of the parameter estimate from the regression model on the complete dataset. PMM's estimate is the least biased of the three. These results are also expected. Under MCAR with missingness in the response only, listwise deletion, least squares, and PMM all produce unbiased estimates for the parameter of interest (Van Buuren, ch. 1.3.8; ch 3.4). 

The small bias in this example stems from the fact that the researchers apply this process to only one randomly generated dataset. While out of scope for this study, a researcher could conduct a monte carlo simulation, repeating the process in Example 1 for thousands datasets generated using the same multivariate normal distribution and averaging the bias from each simulation. Such a study would produce a distribution for bias itself, and that distribution should be centered around 0, indicating that each imputation method leads to unbiased parameter estimates on average in analysis models. 

Next, the authors examine the impact of imputation methods on the variance of parameter estimates. Mean imputation produces similar standard error and variance as the full regression model, because mean imputation does not produce any variability between imputations. Results from least squares are even worse. The standard error and variance of coefficient estimates shrink significantly. This phenomenon stems from the fact that least squares imputation increases the correlation between features and the imputed variable. As a result, the variability of the imputed data is understated, and the resulting standard error of the coefficient estimate is far too low. This underestimation makes the coefficient seem more statistically significant than it may be. 

Listwise deletion produces larger variance and standard error because the sample size used for the regression model is reduced. PMM imputation, on the other hand, increases the variance and standard error of the coefficient estimates for a different reason than listwise deletion. Notice that PMM is the only method that produces a non-zero value for the variance-between. PMM produces different parameter estimates in each analysis model applied to each of the multiply imputed datasets. Therefore, when the coefficients are pooled, additional variance results between each model's coefficient estimates. This additional variance captures the uncertainty introduced from imputing missing values, given that the true value is not known and actually comes from a distribution itself. 

## Results from Example 2  {.unnumbered}

Next, the authors review the results from a linear regression on the imputed datasets from Example 2. Recall that Example 2 contains 40% missingness in the predictor $x$, and the missingness mechanism is now MAR.

First, listwise delete:

```{r mar-listwise-delete, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MAR: Listwise Delete"}
include_graphics(path = "figure/mar-listwise-delete.jpg")
```

Next, mean imputation:

```{r mar-mean, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MAR: Mean Imputation"}
include_graphics(path = "figure/mar-mean.jpg")
```

Next, least squares imputation:

```{r mar-ls, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MAR: Least Squares Imputation"}
include_graphics(path = "figure/mar-ls.jpg")
```

Finally, pmm imputation:

```{r mar-pmm, echo=FALSE, out.width="400px", fig.align="center", fig.cap="Linear Regression Results under MAR: PMM Imputation"}
include_graphics(path = "figure/mar-pmm.jpg")
```

## Findings from Example 2 {.unnumbered}

In example 2, the missing data mechanism is MAR and right-tailed. Therefore, the probability of missingness in $x$ increases with larger values of $y$. The bias in mean imputation improves because $x$ is a predictor. That being said, the authors have already addressed why the method is suboptimal because of its disregard for the relationships between variables. Therefore, the authors focus on the results from the other missing data methods instead. 

First, note that the coefficient estimates from listwise deletion are now negatively biased. When more predictors are missing for higher values of $y$, then the underlying dataset's correlation subsides, distorting the true relationship between $x$ and $y$. For right-tailed MAR, listwise deletion ends up producing negatively biased estimates as a result.

Least squares regression, on the other hand, produces a coefficient that is grossly overbiased. This result occurs because the error distribution of the least squares imputation model is not a normal distribution with $\mu=0$, as the imputation model's predictions are postively biased. Under right-tailed MAR with missingness in the predictor, least squares imputation will always lead to postively biased coefficient estimates. This phenomenom is best explained by comparing the scatterplot for least squares imputations found in Example 1 and Example 2.

PMM is the only method that produces an unbiased estimate for the coefficient. PMM produces imputations that follow the missing data mechanism at hand, and thus it preserves the relationship between $x$ and $y$. The analysis model then performs well, and the coefficients are unbiased.

The analysis of variance is similar to example 1. In general, listwise deletion prior to analysis always enlarges the coefficient variance and standard error because the sample size is reduced. Mean imputation ignores any variability between imputations, and least squares inflates correlation between features, thus deflating the standard error and variance of a parameter estimate. PMM is the only method that retains the variability introduced from multiple imputation, and thus it increases standard error to account for the underlying uncertainty in the true value of missing data points.

## Inference from Examples {.unnumbered}

Whenever a researcher fits a supervised machine learning model of imputed data, he or she should be concerned with potential bias of the coefficient estimates and possible understatement or coefficient standard error. The examples above show that bias and standard error are the direct result of how imputation methods respond to the nature of missing data and if they handle the missing data mechanism correctly. 

The researcher should always select the method that produces the best results from the analysis model. The best results stem from an imputation method that preserves the covariance structure of the underlying data. Therefore, in Example 2, the researcher should feel comfortable selecting PMM as the best missing data method to use. In the case where numerous imputation methods lead to unbiased parameter estimates and sufficient standard error for coefficients, the researcher must then consider other factors related to the underlying missing data method. In the MCAR example, both PMM and listwise deletion do a good job. But PMM is computationally expensive, and the results from PMM vary each time the researcher imputes the data (assuming no seed is set). In this case, listwise deletion may actually be prefered. 

These examples demonstrate that there is no free lunch when it comes to analysis of imputed data. The researcher must consider multiple imputation models and assess how they affect bias and variance of coefficients. Additionally, the researcher must consider the computational cost of the underlying imputation algorithm and its flexibility to extend to other scenarios with missing data. Some imputation methods can always be rejected, such as mean and least squares imputation. Other methods, however, must be vetted and selected with careful consideration.

<!--chapter:end:03-findings.Rmd-->

# Conclusion {.unnumbered}

In summary, this project demonstrates how complex it is to handle missing data. The authors provide an end-to-end methodology to explore missing data, handling it using missing data methods, and analyze the impact of missing data methods on supervised analysis models. At the beginning of this text, the researchers proposed four key objectives: describe and visualize the extent of the missing value problem; examine factors related to missingness; develop methods to impute missing data; and measure the impact of imputation on inference derived from supervised learning. Throughout this text, the researchers addressed each objective. To address each objective, the researchers used Autoimpute - the open-source Python package the authors created for users grappling with missing data. The Autoimpute package provides methods to explore missingness, implement imputation methods, and analyze their impact on analytical models in a flexible way. 

This report focuses on establishing a solid foundation around the concepts missing data and imputation and demonstrates examples of missing data analysis on different types of missing data. Ultimately, this research provides Python-savy data practitioners a framework to use to explore missingness in their datasets, perform imputation methods, and assess the impact of imputation on analytical models downstream. Hopefully, users of the Autoimpute package are now well equipped to deal with missing data if and when it arises during their own machine learning research.

# Recommendations {.unnumbered}

This research explores missingness and outlines a framework through which a data practitioner can conduct missing data and imputation analysis. The researchers recommend data practitioners use the flexibility, simplicity, and granularity of the Autoimpute package to conduct their own missing data analyses. To start, data practitioners should review the Autoimpute tutorials website to get a better understanding of how the package works and how and end user can get the most out of its functionality. Once familiar with the package, data practitioners should `pip install` the package, which is registered with the Python Packaging Index. Once installed, users should review the source code and start using the package in their own analysis. Links to the Autoimpute webiste, PyPI package distribution, and Github repository appear in Appendix A.

If challenges arise when using the package, researchers should contact the authors, preferably by submitting a bug report, feature request, or pull request depending on the nature of the issue. Lastly, the researchers hope end users give feedback about the Autoimpute package to the authors and share any interesting results found in personal analyses. 

<!--chapter:end:04-conclusion-recommendations.Rmd-->

`r if(knitr:::is_latex_output()) '\\appendix'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!--
If you feel it necessary to include an appendix, it goes here.
-->


# Autoimpute References

`Autoimpute` is an open-source Python package distributed under the MIT license. The package is hosted on github and registered with the official Python Package Index. The authors also host a website that explores Autoimpute in more detail and provides in-depth tutorials on how end-users can get the most out of the package. The table below provides links to the package and the author's website.

```{r appendixa, echo=FALSE, warning=FALSE}
text_tbl <- data.frame(
  Source = c("Github", "PyPI", "Website"),
  Link = c(
    "https://github.com/kearnz/autoimpute",
    "https://pypi.org/project/autoimpute/",
    "https://kearnz.github.io/autoimpute-tutorials/"
  )
)

kable(text_tbl, caption="Autoimpute Sources", booktabs=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13) %>%
  column_spec(1, width="5em")
```

# Missingness Notation Cheatsheet

```{r appendixbnotation, echo=FALSE, warning=FALSE}
text_tbl <- data.frame(
  Notation = c(
    "$n$",
    "$p$",
    "$Y$",
    "$Y_{obs}$",
    "$Y_{mis}$",
    "$y_{ij}$",
    "$R$",
    "$r_{ij}$",
    "$\\psi$",
    "$m$",
    "$I_j$",
    "$O_j$",
    "$Q$",
    "$\\hat Q$",
    "$U$",
    "$\\bar Q$",
    "$\\bar U$",
    "$B$",
    "$T$"
    ),
  Description = c(
    "The number of records or observations in a matrix",
    "The number of columns or features in a matrix",
    "The complete data matrix of observed and missing records",
    "Records within $Y$ that are completely observed for all columns $p$",
    "Records within $Y$ with a missing value in any column in $p$",
    "A scalar value $y$ in row $i$ and column $j$ of matrix $Y$",
    "The missing indicator matrix, where each value $r_{ij} \\in 0,1$",
    "A scalar value $r$ in row $i$ and column $j$ of matrix $R$",
    "The parameters of the missing data model",
    "The number of complete datasets $Y$ to impute independently",
    "The influx coefficient",
    "The outflux coefficient",
    "The population parameter of scientific interest",
    "The estimate for $Q$ using hypothetically complete data",
    "The variance-covariance matrix of estimate $\\hat Q$",
    "The pooled parameter estimate of $Q$ under multiple imputation",
    "The variance-within under multiple imputation",
    "The variance-between under multiple imputation",
    "The total variance under multiple imputation"
  )
)

kable(text_tbl, caption ="Notation", booktabs=TRUE, longtable=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13) %>%
  column_spec(1, width="5em")
```

# Missingess Expression Cheatsheet

```{r appendixcexpressions, echo=FALSE, warning=FALSE}

text_tbl <- data.frame(
  Expression = c(
    "$Y = (Y_{mis}, Y_{obs})$",
    "$r_{ij} = 0$",
    "$r_{ij} = 1$",
    "$P(R\\mid Y_{obs}, Y_{mis},\\psi)$",
    "$P(R=0\\mid Y_{obs},Y_{mis},\\psi) = P(R=0\\mid \\psi)$",
    "$P(R=0\\mid Y_{obs},Y_{mis},\\psi) = P(R=0\\mid Y_{obs}, \\psi)$",
    "$P(Y_{mis}\\mid Y_{obs}, R)$",
    "$P(Y\\mid Y_{obs}, R=1) = P(Y\\mid Y_{obs}, R=0)$",
    "$I_j = \\frac{\\sum_j^p\\sum_k^p\\sum_i^n (1-r_{ij})r_{ik}}{\\sum_k^p\\sum_i^n r_{ik}}$",
    "$O_j = \\frac{\\sum_j^p\\sum_k^p\\sum_i^n r_{ij}(1-r_{ik})}{\\sum_k^p\\sum_i^n 1-r_{ij}}$",
    "$E(\\hat Q|Y) = Q$",
    "$\\bar Q = \\frac{1}{m}\\sum_{\\ell=1}^m \\hat Q_\\ell$",
    "$\\bar U = \\frac{1}{m}\\sum_{\\ell=1}^m \\bar U_\\ell$",
    "$B = \\frac{1}{m-1}\\sum_{\\ell=1}^m (\\hat Q_\\ell-\\bar Q)(\\hat Q_\\ell-\\bar Q)'$",
    "$T = \\bar U + B + \\frac{B}{m}$"
    ),
  Description = c(
    "The complete data matrix equals the conjoined $Y_{obs}$ and $Y_{mis}$",
    "When a value $r_{ij}=0$, the corresponding value $y_{ij}$ is missing",
    "When a value $r_{ij}=1$, the corresponding value $y_{ij}$ is observed",
    "General expression for a missing data model. Also form for MNAR",
    "Reducible form of the missing data model under MCAR",
    "Reducible form of the missing data model under MAR",
    "General expression for an imputation model",
    "Implication of ignorability in which imputation models can safely ignore $\\psi$",
    "The forumla for influx coefficient",
    "The formula for outflux coefficient",
    "The equality necessary for unbiasedness of an estimate $\\hat Q$ conditional on $Y$",
    "The pooled estimate for $Q$ is the mean of $m$ $\\hat Q$ estimates from $m$ imputations",
    "The variance within is the mean of the $m$ $\\hat U$ estimates from $m$ imputations",
    "The variance between is the additional variance in estimating $\\hat Q$ during $m$ imputations",
    "The total variance is the sum of variance within, variance between, and added variance from finite number of imputations $m$"
  )
)

kable(text_tbl, caption="Expressions", booktabs=TRUE, longtable=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13)
```


# Concepts Related to Missingness

```{r appendixdconcepts, echo=FALSE, warning=FALSE}

text_tbl <- data.frame(
  Concept = c(
    "complete data matrix",
    "missing indicator matrix",
    "missing data mechanism",
    "missing data model",
    "MCAR",
    "MAR",
    "MNAR",
    "ignorability",
    "missing data pattern",
    "missing data method",
    "deletion",
    "imputation model",
    "analysis model",
    "target",
    "univariate",
    "multivariate",
    "missing data pattern",
    "single imputation",
    "multiple imputation",
    "influx",
    "outflux",
    "pooled parameter estimate",
    "variance within",
    "variance between",
    "total variance"
    ),
  Definition = c(
    "The complete matrix $Y$, which is comprised of $Y_{obs}$ and $Y_{mis}$",
    "Missing indicator $R$ suggests which values in $Y$ are missing",
    "Process that governs relationship b/w observed and $P(missing)$",
    "Formalizes relationship specified by missing data mechanism",
    "Missing data mechanism depends on $\\psi$ only",
    "Missing data mechanism depends on $Y_{obs}$ and $\\psi$ only",
    "Missing data mechanism depends on $Y_{obs}$, $Y_{mis}$, and $\\psi$",
    "Criteria required for imputation models to ignore $\\psi$",
    "Various ways in which data can be missing throughout a dataset",
    "Method used to handle missing data. Use deletion or imputation",
    "Discard missing values from the dataset",
    "Replace missing values with imputations from imputation model",
    "A supervised machine learning model applied to imputed data",
    "Column with missing values to be imputed",
    "Models using target to determine imputation for target",
    "Models using features to predict imputed values for target",
    "Pattern suggesting information transferrable b/w variables",
    "Impute missing values once prior to analysis",
    "Impute missing values $m$ times prior to analysis",
    "Candidates to be imputed using the other predictors",
    "Variables useful as predictors to impute a target variable",
    "The coefficients of an analysis model under multiple imputation",
    "The average of the variance of the parameter estimate from each imputation",
    "The variance introduced from different parameter estimates across imputations",
    "The accurate representation of variance under multiple imputation"
  )
)

kable(text_tbl, caption="Concepts", booktabs=TRUE, longtable=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13)  %>%
  column_spec(1, width="7em")
```

# Univariate Imputation Methods

```{r appendixeunivar, echo=FALSE, warning=FALSE}

text_tbl <- data.frame(
  Method = c(
    "mean",
    "median",
    "mode",
    "random",
    "norm",
    "categorical",
    "interpolation",
    "last observation carried forward (LOCF)",
    "next observation carried backward (NOCB)"
    ),
  Description = c(
    "Mean imputation finds the mean of observed values in target variable $y$. It then imputes any missing values in $y$ with the observed mean.",
    "Median imputation finds the median of observed values in target variable $y$. It then imputes any missing values in $y$ with the observed median.",
    "Mode imputation finds the mode of observed values in target variable $y$. It then imputes any missing values in $y$ with the observed mode. If multiple modes exist, Autoimpute gives users the option to take the first mode, the last mode, or randomly sample the modes when imputing missing values.",
    "Random imputation imputes each missing value in target $y$ by randomly sampling from the observed values in $y$.",
    "Norm imputation constructs a normal distribution parameterized by the mean and variance of the observed values in target $y$. Missing values are then imputed with random draws from the constructed normal distribution.",
    "Categorical imputation constructs a discrete categorical distribution parameterized by the proportions of each distinct label in target $y$. Missing values are then imputed with draws from the constructed categorical distribution, where the probability of a given label being drawn depends on its proportion within the categorical distribution.",
    "Interpolation imputation constructs new data points within the range of a discrete set of known data points. Autoimpute supports linear, quadratic, cubic, polynomial, and spline interpolation.",
    "LOCF imputes missing values by carrying forward the last observed value. Therefore, the method respects the order of the records in target $y$.",
    "NOCB imputes missing values by carrying backward the next observed value. Therefore, the method respects the order of the records in target $y$."
  )
)

kable(text_tbl, caption="Univariate Methods", booktabs=TRUE, longtable=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13)  %>%
  column_spec(1, width="7em")
```

# Multivariate Imputation Methods

```{r appendixfmultivar, echo=FALSE, warning=FALSE}

text_tbl <- data.frame(
  Method = c(
    "linear regression",
    "binomial logistic regression",
    "multinomial logistic regression",
    "stochastic regression",
    "bayesian linear regression",
    "bayesian binary logistic regression",
    "predictive mean matching (PMM)",
    "local residual draws (LRD)"
    ),
  Description = c(
    "Linear Regression imputation fits a linear model on observed data, where $y$ is the target variable to be imputed and $X$ is the design matrix. The model then finds the records in $X$ where $y$ is missing. These records in $X$ are used to generate predictions from the linear model. Those predictions become the imputations for missing values in $y$",
    "Binary Logistic Regression imputation fits a binary logistic model on observed data, where $y$ is the target variable to be imputed and $X$ is the design matrix. The model then finds the records in $X$ where $y$ is missing. These records in $X$ are used to generate predictions from the binary logistic model. Those predictions become the imputations for missing values in $y$",
    "Multinomial Logistic Regression imputation fits a multinomial logistic model on observed data, where $y$ is the target variable to be imputed and $X$ is the design matrix. The model then finds the records in $X$ where $y$ is missing. These records in $X$ are used to generate predictions from the multinomial logistic model. Those predictions become the imputations for missing values in $y$",
    "Stochastic Regression imputation fits a linear model on observed data, where $y$ is the target variable to be imputed and $X$ is the design matrix. The algorithm then stores a normal distribution for the errors from the fit linear model. The model then finds the records in $X$ where $y$ is missing. These records in $X$ are used to generate predictions from the linear model. For each prediction, the algorithm adds a random draw from the distribution of errors. Those predictions + random draws become the imputations for missing values in $y$",
    "Bayesian linear regression imputation imputes missing values using random draws from the posterior predictive distribution of the missing data $Y_{mis}$. These draws take into account the posterior distribution of the linear model parameters, which in this case are $\\hat{\\beta}$ coefficients.",
    "Bayesian binary logistic regression imputation imputes missing values using random draws from the posterior predictive distribution of the missing data $Y_{mis}$. These draws take into account the posterior distribution of the binary logistic model parameters, which in this care are the probabilities of class membership.",
    "PMM imputation is a multi-step procedure. First, a linear model is fit on the observed data for target $y$ and $X$ to obtain $\\hat{\\beta}$ coefficients. Then, a bayesian model is fit, and the algorithm produces a new set of $\\dot{\\beta}$ coefficients using random draws from the posterior predictive distribution of $\\hat{\\beta}$. The coefficients $\\hat{\\beta}$ are used to make predictions for observed $y$, while $\\dot{\\beta}$ are used to make predictions for missing $y$. For each case where $y$ is missing, the algorithm finds the closest $n$ predicted values among cases where $y$ is observed. The algorithm then randomly samples the $n$ closest predictions, selecting one, and eventually imputes the missing data with the truly observed value of $y$. The standard distance used to measure 'closeness' is manhattan distance. $n$ represents the number of neighbors to find, which generally defaults to 5.",
    "LRD imputation begins by replicating the process for PMM. Once the truly observed value of $y$ is selected through the PMM process, LRD adds the distance to that value. The missing value is then imputed using the sum of the observed value of $y$ and the distance."
  )
)

kable(text_tbl, caption="Multivariate Methods", booktabs=TRUE, longtable=TRUE, escape=FALSE) %>%
  kable_styling(position="left", full_width=TRUE, latex_options=c("hold_position")) %>%
  row_spec(0, bold=TRUE, font_size=13)  %>%
  column_spec(1, width="7em")
```

<!--chapter:end:05-appendix.Rmd-->


<!--
The bib chunk below must go last in this document according to how R Markdown renders.  More info is at http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
-->

\backmatter

<!-- 
If you'd like to change the name of the bibliography to something else,
delete "References" and replace it.
-->

# References {-}

<!--
This manually sets the header for this unnumbered chapter.
-->
\markboth{References}{References}
<!--
To remove the indentation of the first entry.
-->
\noindent

<!--
To create a hanging indent and spacing between entries.  These three lines may need to be removed for styles that don't require the hanging indent.
-->

\setlength{\parindent}{-0.20in}
\setlength{\leftskip}{0.20in}
\setlength{\parskip}{8pt}


<!--
This is just for testing with more citations for the bibliography at the end.  Add other entries into the list here if you'd like them to appear in the bibliography even if they weren't explicitly cited in the document.
-->

---
nocite: | 
  @allison_handling_2012, @allison_handling_2014, @econ_commission, @gelman_data_2017, @introduction_to_sas_notitle_2017, @rubin_inference_1976, @van_buuren_flexible_2018, @morris_tuning_2014, @nakagawa_chapter_2015, @yu_comparative_2017, @vink_towards_nodate, @peng_dong, @xie_measuring_2018, @yin_simulation_based_2015, @lu_robust_2014, @bilogur_missingno_2018, @schouten_generating_2018, @mass_package, @mice_package
...

<!--chapter:end:99-references.Rmd-->

